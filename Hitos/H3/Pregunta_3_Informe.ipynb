{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificador regresion lineal - hito 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente .py contiene las configuraciones, las bases de dato procesadas y algunas funciones que se ocuparan para obtener resultados en el apartado de la pregunta número 3, el código en cuestión se encuentra en los anexos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 50 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from config_p3 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este apartado es mostrar un método alternativo al obtenido en el primer clasificador para asociar palabras a indices de probabilidades de emojis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Diferencias en la base de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La diferencia a mencionar al resto de iteraciones de entrenamiento que se han hecho en el transcurso de este informe es que para el caso de trabajar con una regresión lineal, esta no es capaz de entrenarse para lograr predecir varias clases al mismo tiempo, es por esto que es de suma importancia modificar la base de datos para que esta sea compatible con el clasificador, para esto se transformaran el atributo multiclase que determina que emoji es cada tweet, a varios atributos binarios donde cuando uno es “1” el resto es 0, de esta forma volviendo compatible la base, a continuación se puede ver una tabla donde se puede ver los cambios para ingles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label_0</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_10</th>\n",
       "      <th>label_11</th>\n",
       "      <th>label_12</th>\n",
       "      <th>label_13</th>\n",
       "      <th>label_14</th>\n",
       "      <th>label_15</th>\n",
       "      <th>...</th>\n",
       "      <th>label_19</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "      <th>label_5</th>\n",
       "      <th>label_6</th>\n",
       "      <th>label_7</th>\n",
       "      <th>label_8</th>\n",
       "      <th>label_9</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test0</td>\n",
       "      <td>en Pelham Parkway</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en pelham parkway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test1</td>\n",
       "      <td>The calm before...... | w/ sofarsounds @user |...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>the calm before ... | w / sofarsounds @user | ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test2</td>\n",
       "      <td>Just witnessed the great solar eclipse @ Tampa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>just witnessed the great solar eclipse @ tampa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test3</td>\n",
       "      <td>This little lady is 26 weeks pregnant today! E...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>this little lady is 26 weeks pregnant today ! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test4</td>\n",
       "      <td>Great road trip views! @ Shartlesville, Pennsy...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>great road trip views ! @ shartlesville , penn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  label_0  label_1  \\\n",
       "0  test0                                  en Pelham Parkway        0        0   \n",
       "1  test1  The calm before...... | w/ sofarsounds @user |...        0        0   \n",
       "2  test2  Just witnessed the great solar eclipse @ Tampa...        0        0   \n",
       "3  test3  This little lady is 26 weeks pregnant today! E...        0        1   \n",
       "4  test4  Great road trip views! @ Shartlesville, Pennsy...        0        0   \n",
       "\n",
       "   label_10  label_11  label_12  label_13  label_14  label_15  ...  label_19  \\\n",
       "0         0         0         0         0         0         0  ...         0   \n",
       "1         1         0         0         0         0         0  ...         0   \n",
       "2         0         0         0         0         0         0  ...         0   \n",
       "3         0         0         0         0         0         0  ...         0   \n",
       "4         0         0         0         0         0         0  ...         0   \n",
       "\n",
       "   label_2  label_3  label_4  label_5  label_6  label_7  label_8  label_9  \\\n",
       "0        1        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        1        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0                                  en pelham parkway  \n",
       "1  the calm before ... | w / sofarsounds @user | ...  \n",
       "2  just witnessed the great solar eclipse @ tampa...  \n",
       "3  this little lady is 26 weeks pregnant today ! ...  \n",
       "4  great road trip views ! @ shartlesville , penn...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label_0</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_10</th>\n",
       "      <th>label_11</th>\n",
       "      <th>label_12</th>\n",
       "      <th>label_13</th>\n",
       "      <th>label_14</th>\n",
       "      <th>label_15</th>\n",
       "      <th>...</th>\n",
       "      <th>label_19</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "      <th>label_5</th>\n",
       "      <th>label_6</th>\n",
       "      <th>label_7</th>\n",
       "      <th>label_8</th>\n",
       "      <th>label_9</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>729044324441186304</td>\n",
       "      <td>Selfies for summatime @ Drexel University</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>selfies for summatime @ drexel university</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>663834134037442560</td>\n",
       "      <td>Ready to be a bulldog with rasso #hailstate #i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ready to be a bulldog with rasso #hailstate #i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>747449193350963200</td>\n",
       "      <td>#scored my new #matcotools #slidehammer weight...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#scored my new #matcotools #slidehammer weight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>691439672761925637</td>\n",
       "      <td>@user last night was so much fun @ Skyway Thea...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@user last night was so much fun @ skyway theatre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>758118895618109440</td>\n",
       "      <td>love beach days @ Manasquan Beach</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>love beach days @ manasquan beach</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text  \\\n",
       "0  729044324441186304         Selfies for summatime @ Drexel University    \n",
       "1  663834134037442560  Ready to be a bulldog with rasso #hailstate #i...   \n",
       "2  747449193350963200  #scored my new #matcotools #slidehammer weight...   \n",
       "3  691439672761925637  @user last night was so much fun @ Skyway Thea...   \n",
       "4  758118895618109440                 love beach days @ Manasquan Beach    \n",
       "\n",
       "   label_0  label_1  label_10  label_11  label_12  label_13  label_14  \\\n",
       "0        0        0         0         0         1         0         0   \n",
       "1        0        0         0         0         0         0         1   \n",
       "2        0        0         0         0         0         0         0   \n",
       "3        0        0         0         0         0         0         0   \n",
       "4        0        0         0         0         1         0         0   \n",
       "\n",
       "   label_15  ...  label_19  label_2  label_3  label_4  label_5  label_6  \\\n",
       "0         0  ...         0        0        0        0        0        0   \n",
       "1         0  ...         0        0        0        0        0        0   \n",
       "2         0  ...         0        0        0        0        0        0   \n",
       "3         0  ...         0        0        0        0        0        1   \n",
       "4         0  ...         0        0        0        0        0        0   \n",
       "\n",
       "   label_7  label_8  label_9  \\\n",
       "0        0        0        0   \n",
       "1        0        0        0   \n",
       "2        0        0        0   \n",
       "3        0        0        0   \n",
       "4        0        0        0   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0          selfies for summatime @ drexel university  \n",
       "1  ready to be a bulldog with rasso #hailstate #i...  \n",
       "2  #scored my new #matcotools #slidehammer weight...  \n",
       "3  @user last night was so much fun @ skyway theatre  \n",
       "4                  love beach days @ manasquan beach  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_train2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Para las siguientes iteraciones de entrenamientos, se consideraron mínimos óptimos de palabras obtenidos en el primer clasificador multinomial naive bayes, donde para ingles el optimo es 5 palabras y 10 para español. \n",
    "\n",
    "Cabe destacar que el algoritmo de regresión lineal cuando genera una predicción que un emoji no pertenece a un tweet, este al ser de carácter binario, la regresión dice que es cualquier otro emoji, sin especificar cual, a diferencia del MulitinomialNB donde si se predice que un emoji no pertenece a cierto tweet, es porque el clasificador esta prediciendo que es otro en específico, lo que hace que comparar cual método es mejor, no es justo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión lineal en ingles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo siguiente es un ejemplo de aplicar una regresión para el label del arbol de navidad, donde se va a buscar obtener los valores de los coeficientes de la regresión lineal, pero antes se va a analizar si la RL es capaz de predecir algo o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo de regresión lineal para el label 17\n",
    "%time\n",
    "reg.fit(X_train_bow, df_us_train2[\"label_17\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4337708335088303"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(X_train_bow, df_us_train2[\"label_17\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regresión lineal cuando predice, entrega un número cercano entre 0 y 1, que consiste básicamente en la suma de los coeficientes de las palabras presentes en los tweets que se están prediciendo, por lo tanto, si se quieren utilizar métricas como por ejemplo: precision, recall o f1-score, es importante implementar una función de “cutoff” donde se va a considerar un umbral donde el algoritmo predijo “si”(1) o que “no”(0). Para que sea simple, se estimara que si la predicción (suma de coeficientes beta) de la regresión es mayor a 0,5 entonces se considera que, para ese tweet del test, existe suficiente seguridad para decir que el emoji corresponde al tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.9804392029280196, 'recall': 0.995108863894335, 'f1-score': 0.9877195677779484, 'support': 48455}, '1': {'precision': 0.7109756097560975, 'recall': 0.3773462783171521, 'f1-score': 0.49302325581395345, 'support': 1545}, 'accuracy': 0.97602, 'macro avg': {'precision': 0.8457074063420585, 'recall': 0.6862275711057435, 'f1-score': 0.740371411795951, 'support': 50000}, 'weighted avg': {'precision': 0.9721127778990071, 'recall': 0.97602, 'f1-score': 0.9724334517382609, 'support': 50000}}\n"
     ]
    }
   ],
   "source": [
    "y_pred = reg.predict(X_test_bow) # Ejemplo de lo que se obtiene la predecir con el cutoff en el label 17\n",
    "Puntodecorte = 0.5 # punto del cutoff\n",
    "y_predcut = cutoff(y_pred, Puntodecorte)\n",
    "print(classification_report(df_us_test2[\"label_17\"], y_predcut,output_dict = True ))\n",
    "# Nos interesa la clase 1, ya que ahi se pone a prueba si se esta adivinando el emoji en cuestión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ❤ | Precisión = 0.6235406602254429 | Recall = 0.1481982035856526 | f1-score = 0.2394789482330431 | ❤ |\n",
      "None\n",
      "| 😍 | Precisión = 0.680140597539543 | Recall = 0.03781697366492402 | f1-score = 0.07165008099976858 | 😍 |\n",
      "None\n",
      "| 😂 | Precisión = 0.7563370403767158 | Recall = 0.18687493811268444 | f1-score = 0.29970026003930367 | 😂 |\n",
      "None\n",
      "| 💕 | Precisión = 0.7111111111111111 | Recall = 0.006402881296583463 | f1-score = 0.0126914877794854 | 💕 |\n",
      "None\n",
      "| 🔥 | Precisión = 0.764804469273743 | Recall = 0.2732262249276519 | f1-score = 0.40261745459892645 | 🔥 |\n",
      "None\n",
      "| 😊 | Precisión = 0.8666666666666667 | Recall = 0.0028118747634239983 | f1-score = 0.005605562442731634 | 😊 |\n",
      "None\n",
      "| 😎 | Precisión = 0.7356948228882834 | Recall = 0.015764582238570676 | f1-score = 0.030867726077512286 | 😎 |\n",
      "None\n",
      "| ✨ | Precisión = 0.7250996015936255 | Recall = 0.039308855291576676 | f1-score = 0.07457488219627126 | ✨ |\n",
      "None\n",
      "| 💙 | Precisión = 0.7667560321715817 | Recall = 0.022587268993839837 | f1-score = 0.043881856540084384 | 💙 |\n",
      "None\n",
      "| 😘 | Precisión = 0.6116504854368932 | Recall = 0.004971983268881698 | f1-score = 0.00986378581493659 | 😘 |\n",
      "None\n",
      "| 📷 | Precisión = 0.7908496732026143 | Recall = 0.027848101265822784 | f1-score = 0.053801689639839924 | 📷 |\n",
      "None\n",
      "| 🇺🇸 | Precisión = 0.8563023308440824 | Recall = 0.32182343936043545 | f1-score = 0.4678246893738023 | 🇺🇸 |\n",
      "None\n",
      "| ☀ | Precisión = 0.7122108660570199 | Recall = 0.12591535901093676 | f1-score = 0.21399709067399386 | ☀ |\n",
      "None\n",
      "| 💜 | Precisión = 0.7435424354243543 | Recall = 0.040715296019397856 | f1-score = 0.07720306513409961 | 💜 |\n",
      "None\n",
      "| 😉 | Precisión = 0.7631578947368421 | Recall = 0.002713069510711947 | f1-score = 0.005406917125011654 | 😉 |\n",
      "None\n",
      "| 💯 | Precisión = 0.744413407821229 | Recall = 0.04965530091298677 | f1-score = 0.09310043668122271 | 💯 |\n",
      "None\n",
      "| 😁 | Precisión = 0.7843137254901961 | Recall = 0.003818980332251289 | f1-score = 0.0076009501187648465 | 😁 |\n",
      "None\n",
      "| 🎄 | Precisión = 0.7267377712394263 | Recall = 0.39642892968201426 | f1-score = 0.5130135652625429 | 🎄 |\n",
      "None\n",
      "| 📸 | Precisión = 0.7388535031847133 | Recall = 0.01081988620464509 | f1-score = 0.02132744989887847 | 📸 |\n",
      "None\n",
      "| 😜 | Precisión = 0.8333333333333334 | Recall = 0.001032844453625284 | f1-score = 0.0020631318341242004 | 😜 |\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "metrica_clase1_todos( X_train_bow , df_us_train2)     # Punto de corte 50%    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se encuentran resultados mas altos de lo esperado en la precision, sin embargo el recall es muy bajo, por lo tanto el algoritmo de regresión lineal falla mucho en los falsos negativos ( Dice que no es el emoji, pero en realidad si es), a cambio de tener una precisión más alta. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para encontrar el top de palabras, vamos a predecir y luego este valor de predicción va a corresponder al valor que la regresión le asocio al coeficiente de cada regresión como ya se dijo en los parrafos anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.49 s\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(X_train_bow, df_us_train2[\"label_17\"])\n",
    "vocab_length = X_train_bow.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17777\n",
      "17777\n"
     ]
    }
   ],
   "source": [
    "print(reg.coef_.size)\n",
    "print(vocab_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos aseguramos de que el largo del vocabulario este en sintonía con la cantidad de coeficientes para tener evidencia de que el largo del vocabulario se relacióna con los coeficientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎄\n",
      "(['ohchristmastree', 'holidaze', 'litmas', 'xmas2015', 'xmas2016'], array([0.54584545, 0.57313968, 0.62446983, 0.7050567 , 0.76373461]))\n"
     ]
    }
   ],
   "source": [
    "ejemplo_navidad_us()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apoyandonos con la métodologia propuesta, recordamos el modelo:\n",
    "\n",
    "\n",
    "$$ Y1_{emoji}=β_{0}+β_{1} X_{1}+ ε $$ \n",
    "\n",
    "Donde Y es el emoji que se quiere predecir (variable binaria) \n",
    "\n",
    "Donde X nos dice si la palabra X esta presente en el tweet o no ( variable binaria) \n",
    "\n",
    "Donde β el valor probabilistico cuando esta la palabra X y como aporta en predecir Y  \n",
    "\n",
    "Donde n es la cantidad de palabras que existen en todos los tweets \n",
    "\n",
    "Tomando el modelo Y1, vemos si utilizando los resultados obtenidos, es posible plantear el indice de probabilidad de cada palabra en un regresión, para esto se utlizara como ejemplo la palabra \"litmas\":\n",
    "\n",
    "$$ Y1_{ArbolNavidad}=β_{Intercepto}+β_{litmas} X_{Contiene litmas?}+ ε $$ \n",
    "$$ Y1_{ArbolNavidad} = β_{Intercepto} + 0.6244698 * 1 +  ε $$\n",
    "\n",
    "Si aproximamos el intercepto y el error a 0, entonces nos queda lo siguiente:\n",
    "\n",
    "$$ Y1_{ArbolNavidad} ≈ 0.6244698 $$\n",
    "\n",
    "Entonces si multiplicamos por 100 el coeficiente obtenemos finalmente que:\n",
    "\n",
    "$$ Y1_{ArbolNavidad} ≈ 62.44 \\% $$\n",
    "\n",
    "Obteniendo de esta manera el indice de probabilidad asociado a una palabra para una regresión lineal. Lo siguiente es repetir el top de palabras para cada emoji de la base de datos, para de esta forma encontrar más indices de probabilidades asociados a palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❤\n",
      "{'sibabes': 0.804948529378079, 'snowwhite': 0.8203815604017426, '1luv': 0.9551082292107682, 'cityofbrotherlylove': 1.0276042069771996, 'kfodiaries': 0.9732962170496406}\n",
      "😍\n",
      "{'asada': 0.6821768010788973, 'gyu': 0.8567913547961459, 'enamorada': 0.764880037442025, 'eatgood': 0.8798387923167201, 'encanta': 0.6974620745801943}\n",
      "😂\n",
      "{'lmfaoooo': 0.7756739280963982, 'foolin': 0.7836170807026172, 'hysterical': 0.8031867993103163, 'postavideoyoucantexplain': 0.9092025087300106, 'clownin': 0.980526728422956}\n",
      "💕\n",
      "{'froomies': 0.4184682101946456, 'twinny': 0.5270839756126672, 'endorsement': 0.5009280482968419, 'honeybglam': 0.5480836741094768, 'bakers': 0.42597044968754366}\n",
      "🔥\n",
      "{'linkinmybio': 0.7315935943422897, 'fiya': 0.748510479195848, 'feeltheburn': 0.8444973901079282, 'instant_classic': 0.845625695616753, 'onfire': 0.9160725933546516}\n",
      "😊\n",
      "{'iah': 0.35770813114790895, 'allah': 0.3617374629968806, 'snowglobe': 0.38610150714220465, 'trigger': 0.46180553488716364, 'goodtime': 0.528529456916411}\n",
      "😎\n",
      "{'sunglasses': 0.5126454429948464, 'blackink': 0.5286790964118758, 'eyewear': 0.5434584721404843, 'raybans': 0.5520319238294865, 'digg': 0.7018821072245504}\n",
      "✨\n",
      "{'sparkle': 0.5078864907011988, 'hairbyme': 0.5264032318326115, 'mmxvi': 0.7225511419982117, 'hing': 1.0060537214014587, 'getonshimmur': 1.0163760125382462}\n",
      "💙\n",
      "{'bleedblue': 0.5626547318846709, 'leafs': 0.576885912936696, 'goroyals': 0.6973954292642884, 'itsaboy': 0.8644660797994382, 'foreverroyal': 0.5839502499197655}\n",
      "😘\n",
      "{'dirty30': 0.40593508808949835, 'besos': 0.4624433416137092, 'smooch': 0.7433733117058802, 'kissy': 0.5839960133957334, 'smooches': 0.7004524697601264}\n",
      "📷\n",
      "{'itsamazingoutthere': 0.657163770529224, 'conquer_la': 0.7277235711382505, 'acmecups': 0.8048222312349016, 'gdlfashion': 0.867047694685142, 'bvillain': 0.8659278688433318}\n",
      "🇺🇸\n",
      "{'holidayweekend': 0.6714730537801867, 'merica': 0.6816245743990132, 'weremember': 0.9377555005483801, 'madeintheusa': 0.707259173459025, 'happyfourth': 0.8736067226124485}\n",
      "☀\n",
      "{'floatin': 0.49781993475665387, 'sunshine': 0.5057195505238388, 'beachin': 0.5159139132987594, 'summerdays': 0.6019658374060001, 'photographer_serena': 0.9165463395683624}\n",
      "💜\n",
      "{'purplerain': 0.49781832643730695, 'endalz': 0.9051558304928538, 'purple': 0.510798755086326, 'tarleton': 0.5692994389083341, 'alzheimer': 0.6110837084904401}\n",
      "😉\n",
      "{'biased': 0.3531183468871711, 'phrase': 0.35464262088176274, 'womeninbusiness': 0.42862072015241254, 'backtowork': 0.4913070571230622, 'mividaesunatombola': 0.9969868506495924}\n",
      "💯\n",
      "{'rns': 0.6950447266941573, 't3t': 0.9111738165299632, 'keepit': 0.9490891453084365, 'eclecticeatery': 0.9980959849941287, 'childrenofthekorn': 0.9425514864079221}\n",
      "😁\n",
      "{'dentistry': 0.3537264665926751, 'podium': 0.35882469352312285, 'cheesin': 0.36385308847092396, 'thurgood': 0.457619239427909, 'djsty': 0.7692368005133594}\n",
      "🎄\n",
      "{'ohchristmastree': 0.5458454544210048, 'holidaze': 0.573139678861416, 'litmas': 0.6244698272628743, 'xmas2015': 0.7050566972648991, 'xmas2016': 0.763734613387404}\n",
      "📸\n",
      "{'mista': 0.3979439325666228, 'andaz': 0.4199207292743972, 'vagabond': 0.4402662810995539, 'banshee': 0.5627320549463201, 'mugshot': 0.47408596900504907}\n",
      "😜\n",
      "{'guessed': 0.3017456109296402, 'punny': 0.3831077915871773, 'dontjudgeme': 0.3260156091195437, 'warmup': 0.312748715535042, 'wacky': 0.31769729139819836}\n"
     ]
    }
   ],
   "source": [
    "Listatop_us() # Función que entrega el TOP de palabras por emojis en us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente se encontro otro clasificador que puede relacionar cada palabra frecuente de un idioma a una probabilidad, si bien ya se habian encontrado probabilidades asociadas a palabras mediante el clasificador MultinomialNB, ahora se obtiene resultados mediante los coeficientes de la regresión lineal que relacionan a cada palabra con una probabilidad, lo siguiente es repetir el codigo para español."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión lineal en español"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entreno el modelo en ingles, ahora se entrenara para español y se buscara y existe algunas diferencias relevantes o si esque tienene comportamientos similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ❤ | Precisión = 0.7001746071339486 | Recall = 0.17432617066202957 | f1-score = 0.2791507135398538 | ❤ |\n",
      "None\n",
      "| 😍 | Precisión = 0.7580967612954818 | Recall = 0.16589377898328814 | f1-score = 0.27221823402727924 | 😍 |\n",
      "None\n",
      "| 😂 | Precisión = 0.823321554770318 | Recall = 0.24129449838187703 | f1-score = 0.3732105315847432 | 😂 |\n",
      "None\n",
      "| 💕 | Precisión = 0.8317757009345794 | Recall = 0.03328347045624533 | f1-score = 0.06400575332614168 | 💕 |\n",
      "None\n",
      "| 😊 | Precisión = 0.8777777777777778 | Recall = 0.072503671071953 | f1-score = 0.13394370973211256 | 😊 |\n",
      "None\n",
      "| 😘 | Precisión = 0.8726415094339622 | Recall = 0.050546448087431695 | f1-score = 0.09555785123966942 | 😘 |\n",
      "None\n",
      "| 💪 | Precisión = 0.8323765786452354 | Recall = 0.2320742637644046 | f1-score = 0.36295369211514394 | 💪 |\n",
      "None\n",
      "| 😉 | Precisión = 0.8893805309734514 | Recall = 0.06448508180943215 | f1-score = 0.12025127131319174 | 😉 |\n",
      "None\n",
      "| 👌 | Precisión = 0.945054945054945 | Recall = 0.029819694868238558 | f1-score = 0.05781512605042017 | 👌 |\n",
      "None\n",
      "| 🇪🇸 | Precisión = 0.8836915297092288 | Recall = 0.2535364526659412 | f1-score = 0.39402480270574963 | 🇪🇸 |\n",
      "None\n",
      "| 😎 | Precisión = 0.9112426035502958 | Recall = 0.05900383141762452 | f1-score = 0.11083123425692694 | 😎 |\n",
      "None\n",
      "| 💙 | Precisión = 0.881578947368421 | Recall = 0.028425965210012727 | f1-score = 0.05507603781339909 | 💙 |\n",
      "None\n",
      "| 💜 | Precisión = 0.8648648648648649 | Recall = 0.014473089099954772 | f1-score = 0.028469750889679714 | 💜 |\n",
      "None\n",
      "| 😜 | Precisión = 0.9473684210526315 | Recall = 0.039318479685452164 | f1-score = 0.07550335570469799 | 😜 |\n",
      "None\n",
      "| 💞 | Precisión = 1.0 | Recall = 0.007349338559529643 | f1-score = 0.014591439688715955 | 💞 |\n",
      "None\n",
      "| ✨ | Precisión = 0.8636363636363636 | Recall = 0.04735792622133599 | f1-score = 0.0897920604914934 | ✨ |\n",
      "None\n",
      "| 🎶 | Precisión = 0.8868613138686131 | Recall = 0.11505681818181818 | f1-score = 0.2036881810561609 | 🎶 |\n",
      "None\n",
      "| 💘 | Precisión = 0.88 | Recall = 0.011560693641618497 | f1-score = 0.022821576763485476 | 💘 |\n",
      "None\n",
      "| 😁 | Precisión = 0.9473684210526315 | Recall = 0.032682705401724924 | f1-score = 0.06318560772268539 | 😁 |\n",
      "None\n",
      "Wall time: 37.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "map_emojis_es = df_es_mapping[\"label\"].values\n",
    "metrica_clase1_todos_es( X_train_bow_es , df_es_train2)   # Punto de corte 50%    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se encuentran los mismos resultados que en ingles, una precision alta a cambio de un recall muy bajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❤\n",
      "{'weddingdress': 1.0719928400095697, 'guapet': 1.1680646749089834, 'modeloporundia': 1.1946272585010524, 'waterpolo': 1.2259800778188212, 'odon': 1.3557269237896223}\n",
      "😍\n",
      "{'alucinante': 0.7972977290503844, 'ricuras': 0.8068529342025612, 'amordehermanos': 0.8511529327936498, 'sinpalabras': 0.8738627220003872, 'losamo': 1.1657874878322254}\n",
      "😂\n",
      "{'jajajajajajajajajaja': 0.9334058630660954, 'gelida': 0.9436811268432989, 'gelidamenamora': 0.9563973975124452, 'postureomaximo': 1.0545066911169394, 'matata': 0.987014013449593}\n",
      "💕\n",
      "{'teamooooo': 0.5821202017491293, 'distinta': 0.5892009737114164, 'arganzuela': 0.6570108954514027, 'fortuny': 0.6689502521598631, 'valdivia': 0.6781009146416713}\n",
      "😊\n",
      "{'seguirnos': 0.7749594547176322, 'esmorzant': 0.7957428754906615, 'thediyingroom': 0.7966060206892784, 'kikejaen': 0.8263083920231762, 'askdavidparejo': 0.8398547881346923}\n",
      "😘\n",
      "{'guapaaaa': 0.5643463573550496, 'besis': 0.5800697772566662, 'mai': 0.5987995214884582, 'wlwspain': 0.6987068011803832, 'guapaaa': 0.7270796360942113}\n",
      "💪\n",
      "{'campeonas': 0.7402940744375038, 'empujón': 0.7966996498518515, 'powerlifting': 0.8422456695772097, 'vamooos': 1.0069798712090072, 'quiendijomiedo': 0.9961940826712626}\n",
      "😉\n",
      "{'llévate': 0.6443127477172776, 'martivell': 0.6533398000610704, 'azorin': 0.9602786825650533, 'inmensidad': 0.6924809123813698, 'sosimple': 0.7654236002765546}\n",
      "👌\n",
      "{'completito': 0.6056925817429956, 'overa': 0.6070390397951602, 'pitch': 1.0440291172401035, 'sogood': 1.0166076764182004, 'calité': 0.7296461379141441}\n",
      "🇪🇸\n",
      "{'vacacioneseuropa2016': 0.708692632434574, 'twin': 0.9644173232289308, 'mantenerme': 0.7348061706325086, 'madrid_bigcity': 0.8552623341783752, 'minorque': 1.0115212187688403}\n",
      "😎\n",
      "{'beloved': 0.6041865409231387, 'hawkersco': 0.613662339725254, 'domicilio': 0.625671432778848, 'sand': 0.6922308685473466, 'matando': 0.6366875728956807}\n",
      "💙\n",
      "{'almadrava': 0.4929334993443196, 'defreds': 0.4965990096012157, 'espacial': 0.5043458574796433, 'cansaron': 0.5971728913905421, 'madrid2016': 0.5400521652873673}\n",
      "💜\n",
      "{'57': 0.4439503801761064, 'maimona': 0.4693594864018324, 'lavanda': 0.4873235941063568, 'unid': 0.7478709164198714, 'lozoya': 0.5345120255458354}\n",
      "😜\n",
      "{'mete': 0.5801997019867202, 'tiesa': 0.9565956602629269, 'nopuedoparar': 0.7433892718839619, 'gaymen': 0.613696105728071, 'hq': 0.587375224656203}\n",
      "💞\n",
      "{'confirmación': 0.42378494775285963, 'cev': 0.46671294478601677, 'esenciales': 0.5426916084114899, 'pasarela': 0.4611577969392111, 'facultat': 0.43287668663485035}\n",
      "✨\n",
      "{'desigual': 0.46607165339104883, 'mágicas': 0.606093605378112, 'arriesgarse': 0.47492918910515985, 'divide': 0.4978816499343889, 'rebeca': 0.5479354165056451}\n",
      "🎶\n",
      "{'huye': 0.5950199418770179, 'illana': 0.7078761749927265, 'n1canalfiesta11': 0.710854428956339, 'adda': 0.7200651740570589, 'supieran': 0.7779729467616211}\n",
      "💘\n",
      "{'flipas': 0.4325963274479884, 'sorbas': 0.45715618824860316, 'felizzzz': 0.48538503247543086, 'ordino': 0.6049441228137088, 'flechazo': 0.7417974533180478}\n",
      "😁\n",
      "{'fanatic': 0.44388522514391876, 'venimos': 0.4582213052145015, 'pasarse': 0.590921492638719, 'ignus': 0.6348814528995955, 'turística': 0.46961271125447807}\n"
     ]
    }
   ],
   "source": [
    "Listatop_es() # Función que entrega el TOP de palabras por emojis en es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente se obtiene las palabras que son más frecuentes según que emoji en español, a continuación, se desarrollaron tablas resumen que incluyen las 3 palabras más probables que estén asociadas a un emoji para el caso de la Naive-Bayes ( Que se de desarrollo en la primera pregunta) y regresión lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tabla X.** *Ejemplos de Top de palabras por emoji en ingles 🇺🇸 *\n",
    "\n",
    "|       Emoji    |   Palabra    |  Probabilidad    |   Naive-Bayes    | Regresión lineal| \n",
    "|----------------|---------------------|---------|-------|------------|\n",
    "|       😂       |      lmfao                     |  0.884 | ✔️    | |\n",
    "|       😂       |      postavideoyoucantexplain  |  0.901 | ✔️    | |  \n",
    "|       😂       |      lmaooo                    |  0.872 | ✔️    | |\n",
    "|       😂       |      clownin                   |  0.980 |    | ✔️ |\n",
    "|       😂       |      postavideoyoucantexplain  | 0.909  |    | ✔️ |\n",
    "|       😂       |      hysterical                |  0.803 |    | ✔️ |\n",
    "|       🎄       |      christmastree                     |  0.846 | ✔️    | |\n",
    "|       🎄       |      ohchristmastree |  0.845 | ✔️    | |  \n",
    "|       🎄       |      xmas2016                   |  0.828 | ✔️    | |\n",
    "|       🎄       |      xmas2016                  |  0.763|    | ✔️ |\n",
    "|       🎄       |      xmas2015  | 0.705 |    | ✔️ |\n",
    "|       🎄       |      litmas               |  0.624|    | ✔️ |\n",
    "|       🔥       |      flames                    |  0.835 | ✔️    | |\n",
    "|       🔥       |      fuego |  0.823| ✔️    | |  \n",
    "|       🔥       |      instant_classic                  |  0.778| ✔️    | |\n",
    "|       🔥       |      onfire                 |  0.916|    | ✔️ |\n",
    "|       🔥       |      instant_classic  | 0.845|    | ✔️ |\n",
    "|       🔥       |      feeltheburn              |  0.844|    | ✔️ |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tabla X.** *Ejemplos de Top de palabras por emoji en español 🇪🇸 *\n",
    "\n",
    "|       Emoji    |   Palabra    |  Probabilidad    |   Naive-Bayes    | Regresión lineal| \n",
    "|----------------|---------------------|---------|-------|------------|\n",
    "|       😎       |      worldwide                     |  0.641 | ✔️    | |\n",
    "|       😎       |     matando |  0.636 | ✔️    | |  \n",
    "|       😎       |      sunglasses                  |  0.692| ✔️    | |\n",
    "|       😎       |      domicilio                |  0.625|    | ✔️ |\n",
    "|       😎       |      elguay  | 0.660 |    | ✔️ |\n",
    "|       😎       |      optico              |  0.611|    | ✔️ |\n",
    "|       💪       |     empujón                   |  0.693 | ✔️    | |\n",
    "|       💪       |      altafit |  0.670 | ✔️    | |  \n",
    "|       💪       |      gymlife                |  0.664| ✔️    | |\n",
    "|       💪       |      powerlifting                |  0.842|    | ✔️ |\n",
    "|       💪       |     quiendijomiedo | 0.996 |    | ✔️ |\n",
    "|       💪       |      vamooos              |  1.006|    | ✔️ |\n",
    "|       😍       |      losamo                   |  0.684 | ✔️    | |\n",
    "|       😍       |      preciosidad |  0.643| ✔️    | |  \n",
    "|       😍       |      amordehermanos                 |  0.626| ✔️    | |\n",
    "|       😍       |      amordehermanos               |  0.851|    | ✔️ |\n",
    "|       😍       |      sinpalabras | 0.873    | ✔️ |\n",
    "|       😍       |      losamo             |  1.165|    | ✔️ |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver algunos patrones presentes en la tabla de ingles donde para el emoji 😂 \"postavideoyoucantexplain\" tiene con porcentaje muy parecido en ambos ambos clasificadores esto también ocurre para el emoji 🔥 donde instant_classic se repiten pero no con una probabilidad tan cercana, notamos que en ambos casos se repite que sea una palabra compuesta.    \n",
    "\n",
    "Para español vemos que ocurre algo interesante con el emoji 💪 donde la palabra “vamos” tiene un coeficiente mayor 1, al igual que con el emoji 😍 donde “losamos” ocurre lo mismo, significando que hay extrema seguridad que al poner estas palabras encontraremos estos emojis.\n",
    "\n",
    "Finalmente podemos concluir que si se puede asociar una palabra a un índice de probabilidad a un emoji especifico, es más, se lograron obtener por medio de dos clasificadores diferentes. Si se quiere expandir esta pregunta es posible generar ensamblaje de clasificadores, es decir \"mezclar\" las predicciones de varios algoritmos, donde para el contexto de esta pregunta seria parecido a promediar la probabilidad de cada palabra que entregue cada clasificador. Por último, otro acercamiento que se le pudo haber dado es la búsqueda de pares de palabras con los índices más altos de probabilidad según el emoji, y comparar estos resultados con los obtenidos al buscar índices de palabras únicas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f20c33d1910a35bd4e57e72ae45c4ccb5c2a16c01a089293cb3a6910e8ec5b3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
