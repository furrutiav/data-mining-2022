{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificador regresion lineal - pregunta 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set_theme()\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rc('axes', titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('ytick', labelsize=12)\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "plt.rcParams.update({'lines.markeredgewidth': 1})\n",
    "plt.rcParams.update({'errorbar.capsize': 2})\n",
    "\n",
    "file_names = {\n",
    "    \"df_es_mapping\": \"../../Data/mapping/df_es_mapping.pickle\",\n",
    "    \"df_us_mapping\": \"../../Data/mapping/df_us_mapping.pickle\",\n",
    "    \n",
    "    \"df_es_test\": \"../../Data/test/df_es_test.pickle\",\n",
    "    \"df_us_test\": \"../../Data/test/df_us_test.pickle\",\n",
    "    \n",
    "    \"df_es_train\": \"../../Data/train/df_es_train.pickle\",\n",
    "    \"df_us_train\": \"../../Data/train/df_us_train.pickle\",\n",
    "    \n",
    "    \"df_es_trial\": \"../../Data/trial/df_es_trial.pickle\",\n",
    "    \"df_us_trial\": \"../../Data/trial/df_us_trial.pickle\",\n",
    "}\n",
    "\n",
    "# mas imports\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tt = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cargar sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_es_train = pickle.load(open(file_names[\"df_es_train\"], \"rb\"))\n",
    "df_es_trial = pickle.load(open(file_names[\"df_es_trial\"], \"rb\"))\n",
    "df_es_test = pickle.load(open(file_names[\"df_es_test\"], \"rb\"))\n",
    "\n",
    "df_us_train = pickle.load(open(file_names[\"df_us_train\"], \"rb\"))\n",
    "df_us_trial = pickle.load(open(file_names[\"df_us_trial\"], \"rb\"))\n",
    "df_us_test = pickle.load(open(file_names[\"df_us_test\"], \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label_0</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_10</th>\n",
       "      <th>label_11</th>\n",
       "      <th>label_12</th>\n",
       "      <th>label_13</th>\n",
       "      <th>label_14</th>\n",
       "      <th>label_15</th>\n",
       "      <th>...</th>\n",
       "      <th>label_18</th>\n",
       "      <th>label_19</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "      <th>label_5</th>\n",
       "      <th>label_6</th>\n",
       "      <th>label_7</th>\n",
       "      <th>label_8</th>\n",
       "      <th>label_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test0</td>\n",
       "      <td>en Pelham Parkway</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test1</td>\n",
       "      <td>The calm before...... | w/ sofarsounds @user |...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test2</td>\n",
       "      <td>Just witnessed the great solar eclipse @ Tampa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test3</td>\n",
       "      <td>This little lady is 26 weeks pregnant today! E...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test4</td>\n",
       "      <td>Great road trip views! @ Shartlesville, Pennsy...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  label_0  label_1  \\\n",
       "0  test0                                  en Pelham Parkway        0        0   \n",
       "1  test1  The calm before...... | w/ sofarsounds @user |...        0        0   \n",
       "2  test2  Just witnessed the great solar eclipse @ Tampa...        0        0   \n",
       "3  test3  This little lady is 26 weeks pregnant today! E...        0        1   \n",
       "4  test4  Great road trip views! @ Shartlesville, Pennsy...        0        0   \n",
       "\n",
       "   label_10  label_11  label_12  label_13  label_14  label_15  ...  label_18  \\\n",
       "0         0         0         0         0         0         0  ...         0   \n",
       "1         1         0         0         0         0         0  ...         0   \n",
       "2         0         0         0         0         0         0  ...         0   \n",
       "3         0         0         0         0         0         0  ...         0   \n",
       "4         0         0         0         0         0         0  ...         0   \n",
       "\n",
       "   label_19  label_2  label_3  label_4  label_5  label_6  label_7  label_8  \\\n",
       "0         0        1        0        0        0        0        0        0   \n",
       "1         0        0        0        0        0        0        0        0   \n",
       "2         0        0        0        0        0        1        0        0   \n",
       "3         0        0        0        0        0        0        0        0   \n",
       "4         0        0        0        0        0        0        0        0   \n",
       "\n",
       "   label_9  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformamos el atributo multiclase categorico a variables binarias\n",
    "df_us_train2 = pd.get_dummies(df_us_train , columns = [\"label\"])\n",
    "df_us_trial2 = pd.get_dummies(df_us_trial , columns = [\"label\"])\n",
    "df_us_test2 = pd.get_dummies(df_us_test , columns = [\"label\"])\n",
    "#df_us_train2.head()\n",
    "df_us_test2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pre-procesamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 22.9 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label_0</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_10</th>\n",
       "      <th>label_11</th>\n",
       "      <th>label_12</th>\n",
       "      <th>label_13</th>\n",
       "      <th>label_14</th>\n",
       "      <th>label_15</th>\n",
       "      <th>...</th>\n",
       "      <th>label_19</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "      <th>label_5</th>\n",
       "      <th>label_6</th>\n",
       "      <th>label_7</th>\n",
       "      <th>label_8</th>\n",
       "      <th>label_9</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>729044324441186304</td>\n",
       "      <td>Selfies for summatime @ Drexel University</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>selfies for summatime @ drexel university</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>663834134037442560</td>\n",
       "      <td>Ready to be a bulldog with rasso #hailstate #i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ready to be a bulldog with rasso #hailstate #i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>747449193350963200</td>\n",
       "      <td>#scored my new #matcotools #slidehammer weight...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#scored my new #matcotools #slidehammer weight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>691439672761925637</td>\n",
       "      <td>@user last night was so much fun @ Skyway Thea...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@user last night was so much fun @ skyway theatre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>758118895618109440</td>\n",
       "      <td>love beach days @ Manasquan Beach</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>love beach days @ manasquan beach</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text  \\\n",
       "0  729044324441186304         Selfies for summatime @ Drexel University    \n",
       "1  663834134037442560  Ready to be a bulldog with rasso #hailstate #i...   \n",
       "2  747449193350963200  #scored my new #matcotools #slidehammer weight...   \n",
       "3  691439672761925637  @user last night was so much fun @ Skyway Thea...   \n",
       "4  758118895618109440                 love beach days @ Manasquan Beach    \n",
       "\n",
       "   label_0  label_1  label_10  label_11  label_12  label_13  label_14  \\\n",
       "0        0        0         0         0         1         0         0   \n",
       "1        0        0         0         0         0         0         1   \n",
       "2        0        0         0         0         0         0         0   \n",
       "3        0        0         0         0         0         0         0   \n",
       "4        0        0         0         0         1         0         0   \n",
       "\n",
       "   label_15  ...  label_19  label_2  label_3  label_4  label_5  label_6  \\\n",
       "0         0  ...         0        0        0        0        0        0   \n",
       "1         0  ...         0        0        0        0        0        0   \n",
       "2         0  ...         0        0        0        0        0        0   \n",
       "3         0  ...         0        0        0        0        0        1   \n",
       "4         0  ...         0        0        0        0        0        0   \n",
       "\n",
       "   label_7  label_8  label_9  \\\n",
       "0        0        0        0   \n",
       "1        0        0        0   \n",
       "2        0        0        0   \n",
       "3        0        0        0   \n",
       "4        0        0        0   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0          selfies for summatime @ drexel university  \n",
       "1  ready to be a bulldog with rasso #hailstate #i...  \n",
       "2  #scored my new #matcotools #slidehammer weight...  \n",
       "3  @user last night was so much fun @ skyway theatre  \n",
       "4                  love beach days @ manasquan beach  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_us_train2['tokenized_text'] = df_us_train2['text'].str.lower().apply(lambda x: \" \".join(tt.tokenize(x)))\n",
    "df_us_train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_test2['tokenized_text'] = df_us_test2['text'].str.lower().apply(lambda x: \" \".join(tt.tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=10) # minima cantidad de veces que tiene que aparecer una palabra para ser considerado \n",
    "X_train_bow = vectorizer.fit_transform(df_us_train2[\"tokenized_text\"])\n",
    "X_test_bow = vectorizer.transform(df_us_test2[\"tokenized_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "387292"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "X_train_bow.shape[0]\n",
    "#print(X_test_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión lineal en ingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probamos para el label 0\n",
    "%time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train_bow, df_us_train2[\"label_17\"])\n",
    "\n",
    "#reg.predict(np.array([[3, 5]]))\n",
    "#array([16.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4337708335088303"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(X_train_bow, df_us_train2[\"label_17\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17777"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.11338276  0.04996757  0.05058278 ...  0.0382701  -0.02656909\n",
      "  0.01485125]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = reg.predict(X_test_bow)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# y pred no es binario, hay que darle un cuttoff donde aceptemos que el algoritmo acerto, eligimos el 50 % \n",
    "# de esta forma podemos usar metricas tipicas\n",
    "# c = corte\n",
    "\n",
    "# Entonces si el algoritmo predice con un número entre 0 y 1 aprox, \n",
    "def cutoff(lista, c):\n",
    "    i = 0\n",
    "    listanueva = []\n",
    "    for i in lista:\n",
    "        if i > c:\n",
    "            listanueva.append(1)\n",
    "        else:\n",
    "            listanueva.append(0)\n",
    "            \n",
    "    return listanueva       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.9804392029280196, 'recall': 0.995108863894335, 'f1-score': 0.9877195677779484, 'support': 48455}, '1': {'precision': 0.7109756097560975, 'recall': 0.3773462783171521, 'f1-score': 0.49302325581395345, 'support': 1545}, 'accuracy': 0.97602, 'macro avg': {'precision': 0.8457074063420585, 'recall': 0.6862275711057435, 'f1-score': 0.740371411795951, 'support': 50000}, 'weighted avg': {'precision': 0.9721127778990071, 'recall': 0.97602, 'f1-score': 0.9724334517382609, 'support': 50000}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = reg.predict(X_test_bow)\n",
    "\n",
    "Puntodecorte = 0.5 # punto del cuttoff\n",
    "y_predcut = cutoff(y_pred, Puntodecorte)\n",
    "\n",
    "print(classification_report(df_us_test2[\"label_17\"], y_predcut,output_dict = True ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ❤ | Precisión = 0.6235406602254429 | Recall = 0.1481982035856526 | f1-score = 0.2394789482330431 | ❤ |\n",
      "None\n",
      "| 😍 | Precisión = 0.680140597539543 | Recall = 0.03781697366492402 | f1-score = 0.07165008099976858 | 😍 |\n",
      "None\n",
      "| 😂 | Precisión = 0.7563370403767158 | Recall = 0.18687493811268444 | f1-score = 0.29970026003930367 | 😂 |\n",
      "None\n",
      "| 💕 | Precisión = 0.7111111111111111 | Recall = 0.006402881296583463 | f1-score = 0.0126914877794854 | 💕 |\n",
      "None\n",
      "| 🔥 | Precisión = 0.764804469273743 | Recall = 0.2732262249276519 | f1-score = 0.40261745459892645 | 🔥 |\n",
      "None\n",
      "| 😊 | Precisión = 0.8666666666666667 | Recall = 0.0028118747634239983 | f1-score = 0.005605562442731634 | 😊 |\n",
      "None\n",
      "| 😎 | Precisión = 0.7356948228882834 | Recall = 0.015764582238570676 | f1-score = 0.030867726077512286 | 😎 |\n",
      "None\n",
      "| ✨ | Precisión = 0.7250996015936255 | Recall = 0.039308855291576676 | f1-score = 0.07457488219627126 | ✨ |\n",
      "None\n",
      "| 💙 | Precisión = 0.7667560321715817 | Recall = 0.022587268993839837 | f1-score = 0.043881856540084384 | 💙 |\n",
      "None\n",
      "| 😘 | Precisión = 0.6116504854368932 | Recall = 0.004971983268881698 | f1-score = 0.00986378581493659 | 😘 |\n",
      "None\n",
      "| 📷 | Precisión = 0.7908496732026143 | Recall = 0.027848101265822784 | f1-score = 0.053801689639839924 | 📷 |\n",
      "None\n",
      "| 🇺🇸 | Precisión = 0.8563023308440824 | Recall = 0.32182343936043545 | f1-score = 0.4678246893738023 | 🇺🇸 |\n",
      "None\n",
      "| ☀ | Precisión = 0.7122108660570199 | Recall = 0.12591535901093676 | f1-score = 0.21399709067399386 | ☀ |\n",
      "None\n",
      "| 💜 | Precisión = 0.7435424354243543 | Recall = 0.040715296019397856 | f1-score = 0.07720306513409961 | 💜 |\n",
      "None\n",
      "| 😉 | Precisión = 0.7631578947368421 | Recall = 0.002713069510711947 | f1-score = 0.005406917125011654 | 😉 |\n",
      "None\n",
      "| 💯 | Precisión = 0.744413407821229 | Recall = 0.04965530091298677 | f1-score = 0.09310043668122271 | 💯 |\n",
      "None\n",
      "| 😁 | Precisión = 0.7843137254901961 | Recall = 0.003818980332251289 | f1-score = 0.0076009501187648465 | 😁 |\n",
      "None\n",
      "| 🎄 | Precisión = 0.7267377712394263 | Recall = 0.39642892968201426 | f1-score = 0.5130135652625429 | 🎄 |\n",
      "None\n",
      "| 📸 | Precisión = 0.7388535031847133 | Recall = 0.01081988620464509 | f1-score = 0.02132744989887847 | 📸 |\n",
      "None\n",
      "| 😜 | Precisión = 0.8333333333333334 | Recall = 0.001032844453625284 | f1-score = 0.0020631318341242004 | 😜 |\n",
      "None\n",
      "Wall time: 3min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Ahora vemos para cada label\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def metrica_clase1(y_real,y_pred,emoji):\n",
    "    Met_regresion_dict = classification_report(y_real, y_pred , output_dict = True )\n",
    "    return print(\"|\",df_us_mapping[\"emoji\"][emoji],\"|\",\"Precisión =\", Met_regresion_dict.get(\"1\").get(\"precision\"),\"|\", \"Recall =\" ,Met_regresion_dict.get(\"1\").get(\"recall\"),\"|\",\"f1-score =\" ,Met_regresion_dict.get(\"1\").get(\"f1-score\"),\"|\",df_us_mapping[\"emoji\"][emoji],\"|\")\n",
    "\n",
    "Puntodecorte = 0.5 # punto del cuttoff\n",
    "def metrica_clase1_todos(train_bow,df_label):\n",
    "    Puntodecorte = 0.5\n",
    "    i = 0\n",
    "    f = df_label.shape[1]\n",
    "    # el for pasa de i = 0 hasta el 17 maoma\n",
    "    for i in range(f-3):\n",
    "        ###\n",
    "        reg = LinearRegression()\n",
    "        reg.fit(train_bow, df_label[str(\"label_\")+str(i)])\n",
    "        y_predcut = cutoff(reg.predict(train_bow), Puntodecorte)\n",
    "        print (metrica_clase1(df_label[str(\"label_\")+str(i)],y_predcut, i))\n",
    "        \n",
    "metrica_clase1_todos( X_train_bow , df_us_train2)       \n",
    "# AL UTILIZAR COMO PUNTO DE CORTE SOBRE EL 50% QUE SI\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se encuentran resultados mas altos de lo esperado en la precision, pero sin embargo el recall no es muy alto, el algoritmo de regresión lineal falla mucho en los falsos negativos ( Dice que no es el emoji, pero en realidad si es), a cambio de tener una precisión más alta. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para encontrar el top de palabras, vamos a predecir y luego este valor de predicción va a corresponder al valor que la regresión le asocio al coeficiente de cada regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train_bow, df_us_train2[\"label_17\"])\n",
    "vocab_length = X_train_bow.shape[1]\n",
    "proba_matrix = np.array([reg.predict(np.eye(1,vocab_length,k))[0] for k in range(vocab_length)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topPalabras(proba_matrix,emoji_id,k=5):\n",
    "    # retorna las palabras para las cuales el emoji en cuestión tiene mas probabilidad\n",
    "    prob = proba_matrix[:]  # mmm\n",
    "    ind = np.argpartition(prob,-k)[-k:]\n",
    "    val = prob[ind]\n",
    "    palabras = [vectorizer.inverse_transform([np.eye(1,vocab_length,k)[0]])[0][0] for k in ind]\n",
    "    return palabras, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label emoji                              name\n",
      "0      0     ❤                       _red_heart_\n",
      "1      1     😍     _smiling_face_with_hearteyes_\n",
      "10    10     📷                          _camera_\n",
      "11    11    🇺🇸                   _United_States_\n",
      "12    12     ☀                             _sun_\n",
      "13    13     💜                    _purple_heart_\n",
      "14    14     😉                    _winking_face_\n",
      "15    15     💯                  _hundred_points_\n",
      "16    16     😁  _beaming_face_with_smiling_eyes_\n",
      "17    17     🎄                  _Christmas_tree_\n",
      "18    18     📸               _camera_with_flash_\n",
      "19    19     😜        _winking_face_with_tongue_\n",
      "2      2     😂          _face_with_tears_of_joy_\n",
      "3      3     💕                      _two_hearts_\n",
      "4      4     🔥                            _fire_\n",
      "5      5     😊  _smiling_face_with_smiling_eyes_\n",
      "6      6     😎    _smiling_face_with_sunglasses_\n",
      "7      7     ✨                        _sparkles_\n",
      "8      8     💙                      _blue_heart_\n",
      "9      9     😘             _face_blowing_a_kiss_\n",
      "✨\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['ohchristmastree', 'holidaze', 'litmas', 'xmas2015', 'xmas2016'],\n",
       " array([0.54584545, 0.57313968, 0.62446983, 0.7050567 , 0.76373461]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_mapping = pickle.load(open(file_names[\"df_us_mapping\"], \"rb\")).sort_values(\"label\")\n",
    "print(df_us_mapping) \n",
    "i = 17\n",
    "map_emojis = df_us_mapping[\"label\"].values\n",
    "print(df_us_mapping[\"emoji\"][int(map_emojis[i])])\n",
    "topPalabras(proba_matrix,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❤\n",
      "{'sibabes': 0.804948529378079, 'snowwhite': 0.8203815604017426, '1luv': 0.9551082292107682, 'cityofbrotherlylove': 1.0276042069771996, 'kfodiaries': 0.9732962170496406}\n",
      "😍\n",
      "{'asada': 0.6821768010788973, 'gyu': 0.8567913547961459, 'enamorada': 0.764880037442025, 'eatgood': 0.8798387923167201, 'encanta': 0.6974620745801943}\n",
      "📷\n",
      "{'lmfaoooo': 0.7756739280963982, 'foolin': 0.7836170807026172, 'hysterical': 0.8031867993103163, 'postavideoyoucantexplain': 0.9092025087300106, 'clownin': 0.980526728422956}\n",
      "🇺🇸\n",
      "{'froomies': 0.4184682101946456, 'twinny': 0.5270839756126672, 'endorsement': 0.5009280482968419, 'honeybglam': 0.5480836741094768, 'bakers': 0.42597044968754366}\n",
      "☀\n",
      "{'linkinmybio': 0.7315935943422897, 'fiya': 0.748510479195848, 'feeltheburn': 0.8444973901079282, 'instant_classic': 0.845625695616753, 'onfire': 0.9160725933546516}\n",
      "💜\n",
      "{'iah': 0.35770813114790895, 'allah': 0.3617374629968806, 'snowglobe': 0.38610150714220465, 'trigger': 0.46180553488716364, 'goodtime': 0.528529456916411}\n",
      "😉\n",
      "{'sunglasses': 0.5126454429948464, 'blackink': 0.5286790964118758, 'eyewear': 0.5434584721404843, 'raybans': 0.5520319238294865, 'digg': 0.7018821072245504}\n",
      "💯\n",
      "{'sparkle': 0.5078864907011988, 'hairbyme': 0.5264032318326115, 'mmxvi': 0.7225511419982117, 'hing': 1.0060537214014587, 'getonshimmur': 1.0163760125382462}\n",
      "😁\n",
      "{'bleedblue': 0.5626547318846709, 'leafs': 0.576885912936696, 'goroyals': 0.6973954292642884, 'itsaboy': 0.8644660797994382, 'foreverroyal': 0.5839502499197655}\n",
      "🎄\n",
      "{'dirty30': 0.40593508808949835, 'besos': 0.4624433416137092, 'smooch': 0.7433733117058802, 'kissy': 0.5839960133957334, 'smooches': 0.7004524697601264}\n",
      "📸\n",
      "{'itsamazingoutthere': 0.657163770529224, 'conquer_la': 0.7277235711382505, 'acmecups': 0.8048222312349016, 'gdlfashion': 0.867047694685142, 'bvillain': 0.8659278688433318}\n",
      "😜\n",
      "{'holidayweekend': 0.6714730537801867, 'merica': 0.6816245743990132, 'weremember': 0.9377555005483801, 'madeintheusa': 0.707259173459025, 'happyfourth': 0.8736067226124485}\n",
      "😂\n",
      "{'floatin': 0.49781993475665387, 'sunshine': 0.5057195505238388, 'beachin': 0.5159139132987594, 'summerdays': 0.6019658374060001, 'photographer_serena': 0.9165463395683624}\n",
      "💕\n",
      "{'purplerain': 0.49781832643730695, 'endalz': 0.9051558304928538, 'purple': 0.510798755086326, 'tarleton': 0.5692994389083341, 'alzheimer': 0.6110837084904401}\n",
      "🔥\n",
      "{'biased': 0.3531183468871711, 'phrase': 0.35464262088176274, 'womeninbusiness': 0.42862072015241254, 'backtowork': 0.4913070571230622, 'mividaesunatombola': 0.9969868506495924}\n",
      "😊\n",
      "{'rns': 0.6950447266941573, 't3t': 0.9111738165299632, 'keepit': 0.9490891453084365, 'eclecticeatery': 0.9980959849941287, 'childrenofthekorn': 0.9425514864079221}\n",
      "😎\n",
      "{'dentistry': 0.3537264665926751, 'podium': 0.35882469352312285, 'cheesin': 0.36385308847092396, 'thurgood': 0.457619239427909, 'djsty': 0.7692368005133594}\n",
      "✨\n",
      "{'ohchristmastree': 0.5458454544210048, 'holidaze': 0.573139678861416, 'litmas': 0.6244698272628743, 'xmas2015': 0.7050566972648991, 'xmas2016': 0.763734613387404}\n",
      "💙\n",
      "{'mista': 0.3979439325666228, 'andaz': 0.4199207292743972, 'vagabond': 0.4402662810995539, 'banshee': 0.5627320549463201, 'mugshot': 0.47408596900504907}\n",
      "😘\n",
      "{'guessed': 0.3017456109296402, 'punny': 0.3831077915871773, 'dontjudgeme': 0.3260156091195437, 'warmup': 0.312748715535042, 'wacky': 0.31769729139819836}\n",
      "Wall time: 3min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(20):\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X_train_bow, df_us_train2[str(\"label_\")+str(i)])\n",
    "    proba_matrix = np.array([reg.predict(np.eye(1,vocab_length,k))[0] for k in range(vocab_length)])\n",
    "    print(df_us_mapping[\"emoji\"][int(map_emojis[i])])\n",
    "    pal, val = topPalabras(proba_matrix,i)\n",
    "    print(dict([(pal[j],val[j]) for j in range(len(pal))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente se encontro otro clasificador que puede relacionar cada palabra frecuente de un idioma a una probabilidad, si bien ya se habian encontrado probabilidades asociadas a palabras mediante el clasificador MultinomialNB, ahora se obtiene resultados mediante los coeficientes de la regresión lineal que relacionan a cada palabra con una probabilidad, lo siguiente es repetir el codigo para español."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión lineal en español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label_0</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_10</th>\n",
       "      <th>label_11</th>\n",
       "      <th>label_12</th>\n",
       "      <th>label_13</th>\n",
       "      <th>label_14</th>\n",
       "      <th>label_15</th>\n",
       "      <th>...</th>\n",
       "      <th>label_17</th>\n",
       "      <th>label_18</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "      <th>label_5</th>\n",
       "      <th>label_6</th>\n",
       "      <th>label_7</th>\n",
       "      <th>label_8</th>\n",
       "      <th>label_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test0</td>\n",
       "      <td>Buenos días desde Valencia en Comunidad Valenc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test1</td>\n",
       "      <td>Anoche en la #prefería con @user ,mi prima eva...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test2</td>\n",
       "      <td>Porfavor llevarlas a reciclar,necesitamos más ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test3</td>\n",
       "      <td>El vecino roquero que todos queremos tener en ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test4</td>\n",
       "      <td>Es un placer contar con profesionales del sect...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  label_0  label_1  \\\n",
       "0  test0  Buenos días desde Valencia en Comunidad Valenc...        0        0   \n",
       "1  test1  Anoche en la #prefería con @user ,mi prima eva...        0        0   \n",
       "2  test2  Porfavor llevarlas a reciclar,necesitamos más ...        0        0   \n",
       "3  test3  El vecino roquero que todos queremos tener en ...        0        0   \n",
       "4  test4  Es un placer contar con profesionales del sect...        1        0   \n",
       "\n",
       "   label_10  label_11  label_12  label_13  label_14  label_15  ...  label_17  \\\n",
       "0         1         0         0         0         0         0  ...         0   \n",
       "1         0         0         0         0         0         0  ...         0   \n",
       "2         0         0         0         0         0         0  ...         0   \n",
       "3         0         0         0         0         0         0  ...         0   \n",
       "4         0         0         0         0         0         0  ...         0   \n",
       "\n",
       "   label_18  label_2  label_3  label_4  label_5  label_6  label_7  label_8  \\\n",
       "0         0        0        0        0        0        0        0        0   \n",
       "1         0        1        0        0        0        0        0        0   \n",
       "2         0        1        0        0        0        0        0        0   \n",
       "3         0        1        0        0        0        0        0        0   \n",
       "4         0        0        0        0        0        0        0        0   \n",
       "\n",
       "   label_9  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformamos el atributo multiclase categorico a variables binarias\n",
    "df_es_train2 = pd.get_dummies(df_es_train , columns = [\"label\"])\n",
    "df_es_trial2 = pd.get_dummies(df_es_trial , columns = [\"label\"])\n",
    "df_es_test2 = pd.get_dummies(df_es_test , columns = [\"label\"])\n",
    "#df_us_train2.head()\n",
    "df_es_test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_es_train2['tokenized_text'] = df_es_train2['text'].str.lower().apply(lambda x: \" \".join(tt.tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_es_test2['tokenized_text'] = df_es_test2['text'].str.lower().apply(lambda x: \" \".join(tt.tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=5)   # Minimo de 10 ocurrencias para considerar una palabra\n",
    "X_train_bow = vectorizer.fit_transform(df_es_train2[\"tokenized_text\"])\n",
    "X_test_bow = vectorizer.transform(df_es_test2[\"tokenized_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>emoji</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>❤</td>\n",
       "      <td>_red_heart_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>😍</td>\n",
       "      <td>_smiling_face_with_hearteyes_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>😂</td>\n",
       "      <td>_face_with_tears_of_joy_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>💕</td>\n",
       "      <td>_two_hearts_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>😊</td>\n",
       "      <td>_smiling_face_with_smiling_eyes_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>😘</td>\n",
       "      <td>_face_blowing_a_kiss_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>💪</td>\n",
       "      <td>_flexed_biceps_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>😉</td>\n",
       "      <td>_winking_face_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>👌</td>\n",
       "      <td>_OK_hand_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>🇪🇸</td>\n",
       "      <td>_Spain_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>😎</td>\n",
       "      <td>_smiling_face_with_sunglasses_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>💙</td>\n",
       "      <td>_blue_heart_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>💜</td>\n",
       "      <td>_purple_heart_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>😜</td>\n",
       "      <td>_winking_face_with_tongue_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>💞</td>\n",
       "      <td>_revolving_hearts_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>✨</td>\n",
       "      <td>_sparkles_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>🎶</td>\n",
       "      <td>_musical_notes_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>💘</td>\n",
       "      <td>_heart_with_arrow_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>😁</td>\n",
       "      <td>_beaming_face_with_smiling_eyes_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label emoji                              name\n",
       "0      0     ❤                       _red_heart_\n",
       "1      1     😍     _smiling_face_with_hearteyes_\n",
       "2      2     😂          _face_with_tears_of_joy_\n",
       "3      3     💕                      _two_hearts_\n",
       "4      4     😊  _smiling_face_with_smiling_eyes_\n",
       "5      5     😘             _face_blowing_a_kiss_\n",
       "6      6     💪                   _flexed_biceps_\n",
       "7      7     😉                    _winking_face_\n",
       "8      8     👌                         _OK_hand_\n",
       "9      9    🇪🇸                           _Spain_\n",
       "10    10     😎    _smiling_face_with_sunglasses_\n",
       "11    11     💙                      _blue_heart_\n",
       "12    12     💜                    _purple_heart_\n",
       "13    13     😜        _winking_face_with_tongue_\n",
       "14    14     💞                _revolving_hearts_\n",
       "15    15     ✨                        _sparkles_\n",
       "16    16     🎶                   _musical_notes_\n",
       "17    17     💘                _heart_with_arrow_\n",
       "18    18     😁  _beaming_face_with_smiling_eyes_"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_es_mapping = pickle.load(open(file_names[\"df_es_mapping\"], \"rb\"))\n",
    "df_es_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ❤ | Precisión = 0.7001746071339486 | Recall = 0.17432617066202957 | f1-score = 0.2791507135398538 | ❤ |\n",
      "None\n",
      "| 😍 | Precisión = 0.7580967612954818 | Recall = 0.16589377898328814 | f1-score = 0.27221823402727924 | 😍 |\n",
      "None\n",
      "| 😂 | Precisión = 0.823321554770318 | Recall = 0.24129449838187703 | f1-score = 0.3732105315847432 | 😂 |\n",
      "None\n",
      "| 💕 | Precisión = 0.8317757009345794 | Recall = 0.03328347045624533 | f1-score = 0.06400575332614168 | 💕 |\n",
      "None\n",
      "| 😊 | Precisión = 0.8777777777777778 | Recall = 0.072503671071953 | f1-score = 0.13394370973211256 | 😊 |\n",
      "None\n",
      "| 😘 | Precisión = 0.8726415094339622 | Recall = 0.050546448087431695 | f1-score = 0.09555785123966942 | 😘 |\n",
      "None\n",
      "| 💪 | Precisión = 0.8323765786452354 | Recall = 0.2320742637644046 | f1-score = 0.36295369211514394 | 💪 |\n",
      "None\n",
      "| 😉 | Precisión = 0.8893805309734514 | Recall = 0.06448508180943215 | f1-score = 0.12025127131319174 | 😉 |\n",
      "None\n",
      "| 👌 | Precisión = 0.945054945054945 | Recall = 0.029819694868238558 | f1-score = 0.05781512605042017 | 👌 |\n",
      "None\n",
      "| 🇪🇸 | Precisión = 0.8836915297092288 | Recall = 0.2535364526659412 | f1-score = 0.39402480270574963 | 🇪🇸 |\n",
      "None\n",
      "| 😎 | Precisión = 0.9112426035502958 | Recall = 0.05900383141762452 | f1-score = 0.11083123425692694 | 😎 |\n",
      "None\n",
      "| 💙 | Precisión = 0.881578947368421 | Recall = 0.028425965210012727 | f1-score = 0.05507603781339909 | 💙 |\n",
      "None\n",
      "| 💜 | Precisión = 0.8648648648648649 | Recall = 0.014473089099954772 | f1-score = 0.028469750889679714 | 💜 |\n",
      "None\n",
      "| 😜 | Precisión = 0.9473684210526315 | Recall = 0.039318479685452164 | f1-score = 0.07550335570469799 | 😜 |\n",
      "None\n",
      "| 💞 | Precisión = 1.0 | Recall = 0.007349338559529643 | f1-score = 0.014591439688715955 | 💞 |\n",
      "None\n",
      "| ✨ | Precisión = 0.8636363636363636 | Recall = 0.04735792622133599 | f1-score = 0.0897920604914934 | ✨ |\n",
      "None\n",
      "| 🎶 | Precisión = 0.8868613138686131 | Recall = 0.11505681818181818 | f1-score = 0.2036881810561609 | 🎶 |\n",
      "None\n",
      "| 💘 | Precisión = 0.88 | Recall = 0.011560693641618497 | f1-score = 0.022821576763485476 | 💘 |\n",
      "None\n",
      "| 😁 | Precisión = 0.9473684210526315 | Recall = 0.032682705401724924 | f1-score = 0.06318560772268539 | 😁 |\n",
      "None\n",
      "Wall time: 34.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Ahora vemos para cada label\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def metrica_clase1(y_real,y_pred,emoji):\n",
    "    Met_regresion_dict = classification_report(y_real, y_pred , output_dict = True )\n",
    "    return print(\"|\",df_es_mapping[\"emoji\"][emoji],\"|\",\"Precisión =\", Met_regresion_dict.get(\"1\").get(\"precision\"),\"|\", \"Recall =\" ,Met_regresion_dict.get(\"1\").get(\"recall\"),\"|\",\"f1-score =\" ,Met_regresion_dict.get(\"1\").get(\"f1-score\"),\"|\",df_es_mapping[\"emoji\"][emoji],\"|\")\n",
    "\n",
    "Puntodecorte = 0.5 # punto del cuttoff\n",
    "def metrica_clase1_todos(train_bow,df_label):\n",
    "    Puntodecorte = 0.5\n",
    "    i = 0\n",
    "    f = df_label.shape[1]\n",
    "    # el for pasa de i = 0 hasta el 17 maoma\n",
    "    for i in range(f-3):\n",
    "        ###\n",
    "        reg = LinearRegression()\n",
    "        reg.fit(train_bow, df_label[str(\"label_\")+str(i)])\n",
    "        y_predcut = cutoff(reg.predict(train_bow), Puntodecorte)\n",
    "        print (metrica_clase1(df_label[str(\"label_\")+str(i)],y_predcut, i))\n",
    "        \n",
    "metrica_clase1_todos( X_train_bow , df_es_train2)       \n",
    "# AL UTILIZAR COMO PUNTO DE CORTE SOBRE EL 50% QUE SI\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❤\n",
      "{'weddingdress': 1.0719928400095697, 'guapet': 1.1680646749089834, 'modeloporundia': 1.1946272585010524, 'waterpolo': 1.2259800778188212, 'odon': 1.3557269237896223}\n",
      "😍\n",
      "{'alucinante': 0.7972977290503844, 'ricuras': 0.8068529342025612, 'amordehermanos': 0.8511529327936498, 'sinpalabras': 0.8738627220003872, 'losamo': 1.1657874878322254}\n",
      "😂\n",
      "{'jajajajajajajajajaja': 0.9334058630660954, 'gelida': 0.9436811268432989, 'gelidamenamora': 0.9563973975124452, 'postureomaximo': 1.0545066911169394, 'matata': 0.987014013449593}\n",
      "💕\n",
      "{'teamooooo': 0.5821202017491293, 'distinta': 0.5892009737114164, 'arganzuela': 0.6570108954514027, 'fortuny': 0.6689502521598631, 'valdivia': 0.6781009146416713}\n",
      "😊\n",
      "{'seguirnos': 0.7749594547176322, 'esmorzant': 0.7957428754906615, 'thediyingroom': 0.7966060206892784, 'kikejaen': 0.8263083920231762, 'askdavidparejo': 0.8398547881346923}\n",
      "😘\n",
      "{'guapaaaa': 0.5643463573550496, 'besis': 0.5800697772566662, 'mai': 0.5987995214884582, 'wlwspain': 0.6987068011803832, 'guapaaa': 0.7270796360942113}\n",
      "💪\n",
      "{'campeonas': 0.7402940744375038, 'empujón': 0.7966996498518515, 'powerlifting': 0.8422456695772097, 'vamooos': 1.0069798712090072, 'quiendijomiedo': 0.9961940826712626}\n",
      "😉\n",
      "{'llévate': 0.6443127477172776, 'martivell': 0.6533398000610704, 'azorin': 0.9602786825650533, 'inmensidad': 0.6924809123813698, 'sosimple': 0.7654236002765546}\n",
      "👌\n",
      "{'completito': 0.6056925817429956, 'overa': 0.6070390397951602, 'pitch': 1.0440291172401035, 'sogood': 1.0166076764182004, 'calité': 0.7296461379141441}\n",
      "🇪🇸\n",
      "{'vacacioneseuropa2016': 0.708692632434574, 'twin': 0.9644173232289308, 'mantenerme': 0.7348061706325086, 'madrid_bigcity': 0.8552623341783752, 'minorque': 1.0115212187688403}\n",
      "😎\n",
      "{'beloved': 0.6041865409231387, 'hawkersco': 0.613662339725254, 'domicilio': 0.625671432778848, 'sand': 0.6922308685473466, 'matando': 0.6366875728956807}\n",
      "💙\n",
      "{'almadrava': 0.4929334993443196, 'defreds': 0.4965990096012157, 'espacial': 0.5043458574796433, 'cansaron': 0.5971728913905421, 'madrid2016': 0.5400521652873673}\n",
      "💜\n",
      "{'57': 0.4439503801761064, 'maimona': 0.4693594864018324, 'lavanda': 0.4873235941063568, 'unid': 0.7478709164198714, 'lozoya': 0.5345120255458354}\n",
      "😜\n",
      "{'mete': 0.5801997019867202, 'tiesa': 0.9565956602629269, 'nopuedoparar': 0.7433892718839619, 'gaymen': 0.613696105728071, 'hq': 0.587375224656203}\n",
      "💞\n",
      "{'confirmación': 0.42378494775285963, 'cev': 0.46671294478601677, 'esenciales': 0.5426916084114899, 'pasarela': 0.4611577969392111, 'facultat': 0.43287668663485035}\n",
      "✨\n",
      "{'desigual': 0.46607165339104883, 'mágicas': 0.606093605378112, 'arriesgarse': 0.47492918910515985, 'divide': 0.4978816499343889, 'rebeca': 0.5479354165056451}\n",
      "🎶\n",
      "{'huye': 0.5950199418770179, 'illana': 0.7078761749927265, 'n1canalfiesta11': 0.710854428956339, 'adda': 0.7200651740570589, 'supieran': 0.7779729467616211}\n",
      "💘\n",
      "{'flipas': 0.4325963274479884, 'sorbas': 0.45715618824860316, 'felizzzz': 0.48538503247543086, 'ordino': 0.6049441228137088, 'flechazo': 0.7417974533180478}\n",
      "😁\n",
      "{'fanatic': 0.44388522514391876, 'venimos': 0.4582213052145015, 'pasarse': 0.590921492638719, 'ignus': 0.6348814528995955, 'turística': 0.46961271125447807}\n",
      "Wall time: 50.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vocab_length = X_train_bow.shape[1]\n",
    "#proba_matrix = np.array([reg.predict(np.eye(1,vocab_length,k))[0] for k in range(vocab_length)])\n",
    "map_emojis = df_es_mapping[\"label\"].values\n",
    "for i in range(19):\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X_train_bow, df_es_train2[str(\"label_\")+str(i)])\n",
    "    proba_matrix = np.array([reg.predict(np.eye(1,vocab_length,k))[0] for k in range(vocab_length)])\n",
    "    print(df_es_mapping[\"emoji\"][int(map_emojis[i])])\n",
    "    pal, val = topPalabras(proba_matrix,i)\n",
    "    print(dict([(pal[j],val[j]) for j in range(len(pal))]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente se obtiene las palabras que son mas frecuentes según que emoji en español."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f20c33d1910a35bd4e57e72ae45c4ccb5c2a16c01a089293cb3a6910e8ec5b3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
