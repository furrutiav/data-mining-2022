# Pregunta 2

## ¬øPodemos utilizar representaciones vectoriales apropiadas de los tweets y encontrar modelos descriptivos de agrupamiento de datos como clustering capaces de relacionar m√°s aquellos tweets asociados a un mismo emoji?

## Pre√°mbulo
El paradigma tradicional de representaci√≥n vectorial de datos es a trav√©s de un dise√±o manual de atributos. 
En Procesamiento del Lenguaje Natural (PLN) existen varias aproximaciones para representar vectorialmente el texto. 
M√©todos como Bag-of-word y tf-idf son formas rudimentarias de codificar la informaci√≥n del texto. 
Mientras que el uso de word-embeddings como word2vec y modelos del lenguaje como BERT son formas m√°s sofisticadas de hacer lo mismo. 
Pero esta vez, aprovech√°ndose de propiedades m√°s complejas del texto. 
En nuestro caso, nos interesa explorar distintas aproximaciones que puedan vectorizar apropiadamente un tweet. 
Por otro lado, cada uno de los tweets de la base de datos posee un √∫nico emoji asociado. 
El emoji es una de las tantas caracter√≠sticas comunes que relacionan a los tweets. 
Hay caracter√≠sticas desde simples hasta complejas de detectar. 
Una caracter√≠stica simple que nos permite agrupar los tweet es la cantidad de palabras que poseen. 
Con esto, podemos tener dos grupos: aquellos con (1) varias palabras y (2) pocas palabras. 
Caracter√≠sticas complejas suelen ser m√°s dif√≠ciles de detectar, como lo es el sentimiento de un tweet. 
As√≠, podemos tener tres grupos: aquellos con sentimiento (1) positivo, (2) neutro y (3) negativo. 
Ahora bien, estamos interesados en explorar distintos algoritmos de clustering con el objetivo de encontrar aquellos mas apropiados.
Es decir, que sean capaces de traducir grupos diferenciados seg√∫n el √∫nico emoji presente en el tweet tanto para ingl√©s como para espa√±ol. 
Entre los algoritmos a explorar estan: k-means, aglomerativo, gaussian mixtures, dbscan y optics.

## Propuesta metodol√≥gica

En lo que sigue se detallara la propuesta metodol√≥gica ilustrada en la **Figura 1.**

**Figura 1.** *Diagrama de trabajo para analisis de clustering*

<img src="https://github.com/furrutiav/data-mining-2022/blob/main/Hitos/H2/p2_clustering.png" alt="drawing" width="600"/>

Primero, nuestro conjunto de datos esta separado por idioma (Ingles y Espa√±ol) y por particion de ajuste (Entrenamiento/Evaluacion/Prueba). Cada dato consiste en un tweet junto a su etiqueta (indice asociado al emoji). Ahora bien, para utilizar algoritmos de clustering es necesario representar vectorialmente cada tweet. Para esto, consideramos cinco metodos. Tres de estos sirve tanto para Ingles como para Espa√±ol. Estos son: bag-of-word, tf-idf y word2vec. Luego, para Espa√±ol consideramos BETO (BERT pero entrenado con un corpus en espa√±ol). Mientras que para Ingles, consideramos BERTweet (BERT pero entrenado con tweets en ingles). Ver **Tabla 1.** para mas detalles de estos metodos. Brevemente, los primeros dos metodos siguen la forma tradicional de representacion de texto. Mientras que los demas, siguen el paradigma de aprendizaje de representaciones. Estas representaciones provienen de capa especificas en redes neuronales. Por otro lado, aquellos inspirados en BERT, siguen el paradigma de aprendizaje profundo.

**Tabla 1.** *Representaci√≥n del tweet*

|       Notaci√≥n    |   M√©todo      |  üá∫üá∏     |   üá™üá∏    | Libreria |
|-------------------|---------------|---------|--------|----------|
|       BOW         | [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model)                                                            |  ‚úîÔ∏è   |   ‚úîÔ∏è   | [sklearn](https://scikit-learn.org/stable/modules/feature_extraction.html#the-bag-of-words-representation)|
|       TFIDF       | [term-frecuency invert-document-frecuency](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)                                    |  ‚úîÔ∏è    |   ‚úîÔ∏è   | [sklearn](https://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting)           |
| W2V               | [Word2vec](https://en.wikipedia.org/wiki/Word2vec)                                                                          | ‚úîÔ∏è     | ‚úîÔ∏è     | [gensim](https://radimrehurek.com/gensim/models/word2vec.html)                                            |
|       BETO        | [BETO: Spanish BERT](https://github.com/dccuchile/beto)                                                                     |       |   ‚úîÔ∏è   | [ü§ó](https://huggingface.co/dccuchile/bert-base-spanish-wwm-cased)                                |
|       BERTweet    | [BERTweet: A pre-trained language model for English Tweets](https://aclanthology.org/2020.emnlp-demos.2/)                   |  ‚úîÔ∏è    |       | [ü§ó](https://huggingface.co/vinai/bertweet-base)                                                  |

Luego de representar cada tweet como un vector con alguno de los metodos propuestos, consideramos cinco algoritmos distintos para agrupar los datos en clusters. Estos son: k-means, Jerarquico aglomerativo, dbscan, optics y Mixturas Gaussianas. Ver **Tabla 2.** para mas detalle. Se indicaran tantos clusters como emojis, siempre que el metodo lo permita. La idea es encontrar el metodo mas apropiado para nuestra tarea principal (predecir el emoji). Es decir, aquel que mejor agrupe aquellos tweets asociados a un mismo emoji y, al mismo tiempo, distinguir aquellos tweets asociado a un emoji diferente. Para medir esto finalizamos con una evaluacion y visualizacion del clustering.

**Tabla 2.** *Algoritmos de clustering*

|       Notaci√≥n    |   M√©todo      | param: #(clusters) |  Libreria |
|-------------------|---------------|------|---------|
| kMeans           | [k-means](https://en.wikipedia.org/wiki/K-means_clustering)           | ‚úîÔ∏è |[sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans) |
| Agg      | [Agglomerative Hierarchical](https://en.wikipedia.org/wiki/Hierarchical_clustering)      | ‚úîÔ∏è |[sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering) |
| DBSCAN            | [Density-based spatial clustering of applications with noise](https://en.wikipedia.org/wiki/DBSCAN)            | |[sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN) | 
| OPTICS            | [Ordering points to identify the clustering structure](https://en.wikipedia.org/wiki/OPTICS_algorithm)      |  | [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.OPTICS.html#sklearn.cluster.OPTICS) |
| GM  | [Gaussian Mixture](https://en.wikipedia.org/wiki/Mixture_model#Gaussian_mixture_model)  | ‚úîÔ∏è |[sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html#sklearn.mixture.GaussianMixture) |

Para evaluar cuantitativamente el clustering, consideramos siete metricas. Algunas de estas son independientes del metodo, mientras que otras no son validas para ciertos metodos de clustering. Ver **Tabla 3.** para mas detalle. (pendiente)

**Tabla 3.** *M√©tricas de evaluaci√≥n para clustering*

|       Notaci√≥n    |   M√©todo      | kMeans | Agg | DBSCAN | OPTICS | GM |  Libreria |
|-------------------|---------------|--------|-----|--------|--------|----|-----------|
|      Corr         | Correlaci√≥n (Pearson)  |   X    |  X  |   X    |   X    | X  |           |
|      WSS          |                        |   X    |     |        |        |    |           |
|      BSS          |                        |   X    |     |        |        |    |           |
|                   | Silhouette             |   X    |     |        |        |    |           |
|                   | Purity                 |   X    |     |        |        |    |           |
|                   | Entropy                |   X    |     |        |        |    |           |

Ahora bien, para evaluar cualitativamente el clustering, se visualizaran los clusters obtenidos. Sin embargo, como los vectores viven en espacios de dimensiones mayores que dos, es necesario reducir la dimensionalidad de los vectores. Para esto, consideramos tres metodos distintos. Estos son: PCA, tSNE y UMAP. Ver **Tabla 4.** para mas detalle. La idea, es reducirnos a dimensiones interpretables como 2 y 3-dimensiones.

**Tabla 4.** *Reductores de dimensionalidad*

|       Notaci√≥n    |   M√©todo               | Libreria |
|-------------------|------------------------|----------|
|      PCA          | [Principal component analysis](https://en.wikipedia.org/wiki/Principal_component_analysis)  |   [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)       |
|      tSNE         | [t-Distributed Stochastic Neighbor Embedding](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding)  | [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) |
|      UMAP         | [Uniform Manifold Approximation and Projection](https://arxiv.org/abs/1802.03426) | [documentation](https://umap-learn.readthedocs.io/en/latest/) |

Finalmente, este analisis nos dara un entendimento de la dificultad de predecir un emoji. Si los datos no se expresan en grupos diferenciados por el emoji, es decir, que se solapan los grupos de datos para emojis distintos. Entonces, modelos de clasificacion tenderan a obtener un desempe√±o deficiente. Por otro lado, con esta informacion podremos encontrar otro grupos (disintos a los indicados por el emoji) que pudiesen existir en el conjunto de datos. En cambio, si los datos logran expresarse para cierta representacion del texto junto a un metodo de clustering particular, responderemos afirmativamente la pregunta.
