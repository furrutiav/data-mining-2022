{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificador - hito 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from string import punctuation\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rc('axes', titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('ytick', labelsize=12)\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "plt.rcParams.update({'lines.markeredgewidth': 1})\n",
    "plt.rcParams.update({'errorbar.capsize': 2})\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "\n",
    "file_names = {\n",
    "    \"df_es_mapping\": \"../../Data/mapping/df_es_mapping.pickle\",\n",
    "    \"df_us_mapping\": \"../../Data/mapping/df_us_mapping.pickle\",\n",
    "    \n",
    "    \"df_es_test\": \"../../Data/test/df_es_test.pickle\",\n",
    "    \"df_us_test\": \"../../Data/test/df_us_test.pickle\",\n",
    "    \n",
    "    \"df_es_train\": \"../../Data/train/df_es_train.pickle\",\n",
    "    \"df_us_train\": \"../../Data/train/df_us_train.pickle\",\n",
    "    \n",
    "    \"df_es_trial\": \"../../Data/trial/df_es_trial.pickle\",\n",
    "    \"df_us_trial\": \"../../Data/trial/df_us_trial.pickle\",\n",
    "}\n",
    "\n",
    "# mas imports\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer # tokenizer especial para tweets\n",
    "tt = TweetTokenizer()\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cargar sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_es_train = pickle.load(open(file_names[\"df_es_train\"], \"rb\"))\n",
    "df_es_trial = pickle.load(open(file_names[\"df_es_trial\"], \"rb\"))\n",
    "df_es_test = pickle.load(open(file_names[\"df_es_test\"], \"rb\"))\n",
    "\n",
    "df_us_train = pickle.load(open(file_names[\"df_us_train\"], \"rb\"))\n",
    "df_us_trial = pickle.load(open(file_names[\"df_us_trial\"], \"rb\"))\n",
    "df_us_test = pickle.load(open(file_names[\"df_us_test\"], \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pre-procesamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>729044324441186304</td>\n",
       "      <td>Selfies for summatime @ Drexel University</td>\n",
       "      <td>12</td>\n",
       "      <td>selfies for summatime @ drexel university</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>663834134037442560</td>\n",
       "      <td>Ready to be a bulldog with rasso #hailstate #i...</td>\n",
       "      <td>14</td>\n",
       "      <td>ready to be a bulldog with rasso #hailstate #i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>747449193350963200</td>\n",
       "      <td>#scored my new #matcotools #slidehammer weight...</td>\n",
       "      <td>16</td>\n",
       "      <td>#scored my new #matcotools #slidehammer weight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>691439672761925637</td>\n",
       "      <td>@user last night was so much fun @ Skyway Thea...</td>\n",
       "      <td>6</td>\n",
       "      <td>@user last night was so much fun @ skyway theatre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>758118895618109440</td>\n",
       "      <td>love beach days @ Manasquan Beach</td>\n",
       "      <td>12</td>\n",
       "      <td>love beach days @ manasquan beach</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text  \\\n",
       "0  729044324441186304         Selfies for summatime @ Drexel University    \n",
       "1  663834134037442560  Ready to be a bulldog with rasso #hailstate #i...   \n",
       "2  747449193350963200  #scored my new #matcotools #slidehammer weight...   \n",
       "3  691439672761925637  @user last night was so much fun @ Skyway Thea...   \n",
       "4  758118895618109440                 love beach days @ Manasquan Beach    \n",
       "\n",
       "  label                                     tokenized_text  \n",
       "0    12          selfies for summatime @ drexel university  \n",
       "1    14  ready to be a bulldog with rasso #hailstate #i...  \n",
       "2    16  #scored my new #matcotools #slidehammer weight...  \n",
       "3     6  @user last night was so much fun @ skyway theatre  \n",
       "4    12                  love beach days @ manasquan beach  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_train['tokenized_text'] = df_us_train['text'].str.lower().apply(lambda x: \" \".join(tt.tokenize(x)))\n",
    "df_us_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_test['tokenized_text'] = df_us_test['text'].str.lower().apply(lambda x: \" \".join(tt.tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"stopwords_en_withpunct = set(stopwords_en).union(set(punctuation))\n",
    "print(list(stopwords_en_withpunct)[:10])\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train_bow = vectorizer.fit_transform(df_us_train[\"tokenized_text\"])\n",
    "X_test_bow = vectorizer.transform(df_us_test[\"tokenized_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_bow, df_us_train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3913558761864433"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train_bow, df_us_train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>emoji</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>â¤</td>\n",
       "      <td>_red_heart_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ğŸ˜</td>\n",
       "      <td>_smiling_face_with_hearteyes_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>ğŸ“·</td>\n",
       "      <td>_camera_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>ğŸ‡ºğŸ‡¸</td>\n",
       "      <td>_United_States_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>â˜€</td>\n",
       "      <td>_sun_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>ğŸ’œ</td>\n",
       "      <td>_purple_heart_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>ğŸ˜‰</td>\n",
       "      <td>_winking_face_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>ğŸ’¯</td>\n",
       "      <td>_hundred_points_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>ğŸ˜</td>\n",
       "      <td>_beaming_face_with_smiling_eyes_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>ğŸ„</td>\n",
       "      <td>_Christmas_tree_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>ğŸ“¸</td>\n",
       "      <td>_camera_with_flash_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>ğŸ˜œ</td>\n",
       "      <td>_winking_face_with_tongue_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ğŸ˜‚</td>\n",
       "      <td>_face_with_tears_of_joy_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ğŸ’•</td>\n",
       "      <td>_two_hearts_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ğŸ”¥</td>\n",
       "      <td>_fire_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>ğŸ˜Š</td>\n",
       "      <td>_smiling_face_with_smiling_eyes_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>ğŸ˜</td>\n",
       "      <td>_smiling_face_with_sunglasses_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>âœ¨</td>\n",
       "      <td>_sparkles_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>ğŸ’™</td>\n",
       "      <td>_blue_heart_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>ğŸ˜˜</td>\n",
       "      <td>_face_blowing_a_kiss_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label emoji                              name\n",
       "0      0     â¤                       _red_heart_\n",
       "1      1     ğŸ˜     _smiling_face_with_hearteyes_\n",
       "10    10     ğŸ“·                          _camera_\n",
       "11    11    ğŸ‡ºğŸ‡¸                   _United_States_\n",
       "12    12     â˜€                             _sun_\n",
       "13    13     ğŸ’œ                    _purple_heart_\n",
       "14    14     ğŸ˜‰                    _winking_face_\n",
       "15    15     ğŸ’¯                  _hundred_points_\n",
       "16    16     ğŸ˜  _beaming_face_with_smiling_eyes_\n",
       "17    17     ğŸ„                  _Christmas_tree_\n",
       "18    18     ğŸ“¸               _camera_with_flash_\n",
       "19    19     ğŸ˜œ        _winking_face_with_tongue_\n",
       "2      2     ğŸ˜‚          _face_with_tears_of_joy_\n",
       "3      3     ğŸ’•                      _two_hearts_\n",
       "4      4     ğŸ”¥                            _fire_\n",
       "5      5     ğŸ˜Š  _smiling_face_with_smiling_eyes_\n",
       "6      6     ğŸ˜    _smiling_face_with_sunglasses_\n",
       "7      7     âœ¨                        _sparkles_\n",
       "8      8     ğŸ’™                      _blue_heart_\n",
       "9      9     ğŸ˜˜             _face_blowing_a_kiss_"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_mapping = pickle.load(open(file_names[\"df_us_mapping\"], \"rb\")).sort_values(\"label\")\n",
    "df_us_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camilo/miniconda3/envs/datamining_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           â¤       0.26      0.88      0.40     10798\n",
      "           ğŸ˜       0.24      0.15      0.18      4830\n",
      "           ğŸ“·       0.34      0.05      0.08      1432\n",
      "          ğŸ‡ºğŸ‡¸       0.77      0.20      0.32      1949\n",
      "           â˜€       0.42      0.10      0.16      1265\n",
      "           ğŸ’œ       0.82      0.01      0.02      1114\n",
      "           ğŸ˜‰       0.25      0.00      0.00      1306\n",
      "           ğŸ’¯       0.51      0.01      0.03      1244\n",
      "           ğŸ˜       0.50      0.00      0.01      1153\n",
      "           ğŸ„       0.80      0.20      0.32      1545\n",
      "           ğŸ“¸       0.51      0.02      0.03      2417\n",
      "           ğŸ˜œ       0.00      0.00      0.00      1010\n",
      "           ğŸ˜‚       0.30      0.48      0.37      4534\n",
      "           ğŸ’•       0.18      0.00      0.01      2605\n",
      "           ğŸ”¥       0.59      0.26      0.36      3716\n",
      "           ğŸ˜Š       0.11      0.00      0.00      1613\n",
      "           ğŸ˜       0.27      0.02      0.04      1996\n",
      "           âœ¨       0.37      0.02      0.04      2749\n",
      "           ğŸ’™       0.41      0.01      0.02      1549\n",
      "           ğŸ˜˜       0.10      0.00      0.00      1175\n",
      "\n",
      "    accuracy                           0.29     50000\n",
      "   macro avg       0.39      0.12      0.12     50000\n",
      "weighted avg       0.36      0.29      0.20     50000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camilo/miniconda3/envs/datamining_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/camilo/miniconda3/envs/datamining_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test_bow)\n",
    "print(classification_report(df_us_test[\"label\"], y_pred, target_names=df_us_mapping[\"emoji\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {k: v for v, k in enumerate(vectorizer.get_feature_names_out())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "santa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.30575752, 0.12646151, 0.02390757, 0.01609396, 0.04433977,\n",
       "        0.00681741, 0.02228636, 0.00644249, 0.01469118, 0.07926728,\n",
       "        0.01555927, 0.01493329, 0.13462598, 0.03244433, 0.0157918 ,\n",
       "        0.03644817, 0.04698774, 0.0207469 , 0.02034638, 0.01605108]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_test = np.zeros(X_train_bow.shape[1])\n",
    "k = vocab[\"santa\"]\n",
    "vec_test[k] = 1\n",
    "print(vectorizer.inverse_transform([vec_test])[0][0])\n",
    "clf.predict_proba([vec_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top palabras por emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 27min 26s, sys: 28.7 s, total: 1h 27min 55s\n",
      "Wall time: 14min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vocab_length = X_train_bow.shape[1]\n",
    "proba_matrix = np.array([clf.predict_proba(np.eye(1,vocab_length,k))[0] for k in range(vocab_length)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254986\n",
      "(254986, 20)\n"
     ]
    }
   ],
   "source": [
    "print(vocab_length)\n",
    "print(proba_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254986,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "una_linea = proba_matrix[:,3]\n",
    "una_linea.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topPalabras(proba_matrix,emoji_id,k=5):\n",
    "    # retorna las palabras para las cuales el emoji en cuestiÃ³n tiene mas probabilidad\n",
    "    prob = proba_matrix[:,emoji_id]  # mmm\n",
    "    ind = np.argpartition(prob,-k)[-k:]\n",
    "    val = prob[ind]\n",
    "    palabras = [vectorizer.inverse_transform([np.eye(1,vocab_length,k)[0]])[0][0] for k in ind]\n",
    "    return palabras, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’•\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['govote', 'imwithher', 'election2016', 'ivoted', 'merica'],\n",
       " array([0.74029875, 0.75185152, 0.78014814, 0.82630495, 0.84354542]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 3\n",
    "print(df_us_mapping[\"emoji\"][i])\n",
    "topPalabras(proba_matrix,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤\n",
      "{'familyfirst': 0.679562931603362, 'heart': 0.6806708579657281, 'valentine': 0.6857972339930336, 'lovemyfamily': 0.685803484186885, 'loveofmylife': 0.7594289068521658}\n",
      "ğŸ˜\n",
      "{'beignet': 0.47919740788782106, 'obsessed': 0.486856749379889, 'swoon': 0.4978084072950244, 'swooning': 0.5325387862637342, 'gorg': 0.5300040945735083}\n",
      "ğŸ˜‚\n",
      "{'sony': 0.3349669824144724, 'gdlfashion': 0.37337534551598367, 'kae': 0.3859179191618636, 'shredforaliving': 0.39087027038214717, 'bvillain': 0.47826854773146393}\n",
      "ğŸ’•\n",
      "{'govote': 0.7402987474848375, 'imwithher': 0.7518515178366638, 'election2016': 0.7801481398590634, 'ivoted': 0.8263049527529907, 'merica': 0.8435454207090919}\n",
      "ğŸ”¥\n",
      "{'sun': 0.36548880773317577, 'soakin': 0.37805021029035124, 'sunny': 0.38295543509665975, 'beachin': 0.4013070333788539, 'sunshine': 0.4797312481916344}\n",
      "ğŸ˜Š\n",
      "{'snyder': 0.2833568651329064, 'purplerain': 0.43810939694947926, 'purple': 0.44659009787725723, 'ripprince': 0.2837044945845404, 'endalz': 0.3793652536941223}\n",
      "ğŸ˜\n",
      "{'socratrip': 0.1887590731950161, 'wink': 0.19843380245602524, 'azek': 0.2135021733335907, 'silvercriketgentlemensclub': 0.2135021733335907, 'mividaesunatombola': 0.2990223207497427}\n",
      "âœ¨\n",
      "{'t3t': 0.3460949343199459, 'rns': 0.41241007982599903, 'keepin': 0.34809661847903434, 'facts': 0.48370876290302084, 'realtalk': 0.40843695300492494}\n",
      "ğŸ’™\n",
      "{'fcpx': 0.18973617552949906, 'dentistry': 0.2130230723862494, 'braces': 0.2269520189936065, 'djsty': 0.25607296722241146, 'cheesin': 0.2270280318822573}\n",
      "ğŸ˜˜\n",
      "{'tree': 0.46853924430748933, 'tis': 0.5098171816209714, 'christmastree': 0.6942504079359842, 'christmas2015': 0.4735492721076075, 'xmas2016': 0.4892834082303059}\n",
      "ğŸ“·\n",
      "{'cred': 0.2621648276060268, 'grigsby': 0.26627983225515367, 'mag': 0.2728110850954131, 'bricks': 0.28372523003396477, 'opus': 0.3624534866287382}\n",
      "ğŸ‡ºğŸ‡¸\n",
      "{'jewelrydesigner': 0.1365342714807406, 'wacky': 0.1485216365991377, 'neh': 0.15861492886801914, 'cray': 0.16709808798539247, 'nyah': 0.22689264544894414}\n",
      "â˜€\n",
      "{'funny': 0.7561810884444389, 'wtf': 0.7948005938667987, 'hilarious': 0.8201762646834001, 'lmfao': 0.8754104272373411, 'lmao': 0.892768382962841}\n",
      "ğŸ’œ\n",
      "{'pink': 0.3310137410613021, 'endorsement': 0.34287079883940974, 'strides': 0.38144462735408236, 'breast': 0.43521304442059067, 'lovealwaysyje': 0.3536589973560555}\n",
      "ğŸ˜‰\n",
      "{'prod': 0.6908989673961936, 'flame': 0.7038964884495722, 'lit': 0.7078997378397108, 'flames': 0.7160113698241805, 'mixtape': 0.7113905786749813}\n",
      "ğŸ’¯\n",
      "{'7171': 0.29075385571943896, 'worlds2016': 0.29597354438444456, 'bagsbycab': 0.29472000956865374, '802': 0.30378241482557744, '3037': 0.3120385304520712}\n",
      "ğŸ˜\n",
      "{'beautique': 0.35197154436594036, 'eyewear': 0.3576700393918544, 'coolin': 0.39352522956385333, 'sunglasses': 0.509810739747842, 'shades': 0.4047882351042405}\n",
      "ğŸ„\n",
      "{'twinkle': 0.3319895503823694, 'magical': 0.33609672416109304, 'getonshimmur': 0.36553417192013304, 'pixie': 0.3681125470406501, 'sparkle': 0.5019984775188345}\n",
      "ğŸ“¸\n",
      "{'dodger': 0.3324127400992648, 'royals': 0.3712339411059547, 'bbn': 0.38644249311533013, 'foreverroyal': 0.39435706589188474, 'autism': 0.4389555948726788}\n",
      "ğŸ˜œ\n",
      "{'smooch': 0.2508820060247188, 'kissy': 0.2578555771668063, 'princessmailyana': 0.2659150518670729, 'smooches': 0.29511031400205406, 'kisses': 0.2976820657784949}\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(df_us_mapping[\"emoji\"][i])\n",
    "    pal, val = topPalabras(proba_matrix,i)\n",
    "    print(dict([(pal[j],val[j]) for j in range(len(pal))]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f20c33d1910a35bd4e57e72ae45c4ccb5c2a16c01a089293cb3a6910e8ec5b3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('datamining_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
