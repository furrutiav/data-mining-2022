{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificador - hito 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from string import punctuation\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rc('axes', titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('ytick', labelsize=12)\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "plt.rcParams.update({'lines.markeredgewidth': 1})\n",
    "plt.rcParams.update({'errorbar.capsize': 2})\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "\n",
    "file_names = {\n",
    "    \"df_es_mapping\": \"../../Data/mapping/df_es_mapping.pickle\",\n",
    "    \"df_us_mapping\": \"../../Data/mapping/df_us_mapping.pickle\",\n",
    "    \n",
    "    \"df_es_test\": \"../../Data/test/df_es_test.pickle\",\n",
    "    \"df_us_test\": \"../../Data/test/df_us_test.pickle\",\n",
    "    \n",
    "    \"df_es_train\": \"../../Data/train/df_es_train.pickle\",\n",
    "    \"df_us_train\": \"../../Data/train/df_us_train.pickle\",\n",
    "    \n",
    "    \"df_es_trial\": \"../../Data/trial/df_es_trial.pickle\",\n",
    "    \"df_us_trial\": \"../../Data/trial/df_us_trial.pickle\",\n",
    "}\n",
    "\n",
    "# mas imports\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer # tokenizer especial para tweets\n",
    "tt = TweetTokenizer()\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cargar sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_es_train = pickle.load(open(file_names[\"df_es_train\"], \"rb\"))\n",
    "df_es_trial = pickle.load(open(file_names[\"df_es_trial\"], \"rb\"))\n",
    "df_es_test = pickle.load(open(file_names[\"df_es_test\"], \"rb\"))\n",
    "\n",
    "df_us_train = pickle.load(open(file_names[\"df_us_train\"], \"rb\"))\n",
    "df_us_trial = pickle.load(open(file_names[\"df_us_trial\"], \"rb\"))\n",
    "df_us_test = pickle.load(open(file_names[\"df_us_test\"], \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pre-procesamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>729044324441186304</td>\n",
       "      <td>Selfies for summatime @ Drexel University</td>\n",
       "      <td>12</td>\n",
       "      <td>selfies for summatime @ drexel university</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>663834134037442560</td>\n",
       "      <td>Ready to be a bulldog with rasso #hailstate #i...</td>\n",
       "      <td>14</td>\n",
       "      <td>ready to be a bulldog with rasso #hailstate #i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>747449193350963200</td>\n",
       "      <td>#scored my new #matcotools #slidehammer weight...</td>\n",
       "      <td>16</td>\n",
       "      <td>#scored my new #matcotools #slidehammer weight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>691439672761925637</td>\n",
       "      <td>@user last night was so much fun @ Skyway Thea...</td>\n",
       "      <td>6</td>\n",
       "      <td>@user last night was so much fun @ skyway theatre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>758118895618109440</td>\n",
       "      <td>love beach days @ Manasquan Beach</td>\n",
       "      <td>12</td>\n",
       "      <td>love beach days @ manasquan beach</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text  \\\n",
       "0  729044324441186304         Selfies for summatime @ Drexel University    \n",
       "1  663834134037442560  Ready to be a bulldog with rasso #hailstate #i...   \n",
       "2  747449193350963200  #scored my new #matcotools #slidehammer weight...   \n",
       "3  691439672761925637  @user last night was so much fun @ Skyway Thea...   \n",
       "4  758118895618109440                 love beach days @ Manasquan Beach    \n",
       "\n",
       "  label                                     tokenized_text  \n",
       "0    12          selfies for summatime @ drexel university  \n",
       "1    14  ready to be a bulldog with rasso #hailstate #i...  \n",
       "2    16  #scored my new #matcotools #slidehammer weight...  \n",
       "3     6  @user last night was so much fun @ skyway theatre  \n",
       "4    12                  love beach days @ manasquan beach  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_train['tokenized_text'] = df_us_train['text'].str.lower().apply(lambda x: \" \".join(tt.tokenize(x)))\n",
    "df_us_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_test['tokenized_text'] = df_us_test['text'].str.lower().apply(lambda x: \" \".join(tt.tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"stopwords_en_withpunct = set(stopwords_en).union(set(punctuation))\n",
    "print(list(stopwords_en_withpunct)[:10])\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=5)\n",
    "X_train_bow = vectorizer.fit_transform(df_us_train[\"tokenized_text\"])\n",
    "X_test_bow = vectorizer.transform(df_us_test[\"tokenized_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_bow, df_us_train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39701310639001064"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train_bow, df_us_train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>emoji</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>â¤</td>\n",
       "      <td>_red_heart_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ğŸ˜</td>\n",
       "      <td>_smiling_face_with_hearteyes_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>ğŸ“·</td>\n",
       "      <td>_camera_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>ğŸ‡ºğŸ‡¸</td>\n",
       "      <td>_United_States_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>â˜€</td>\n",
       "      <td>_sun_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>ğŸ’œ</td>\n",
       "      <td>_purple_heart_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>ğŸ˜‰</td>\n",
       "      <td>_winking_face_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>ğŸ’¯</td>\n",
       "      <td>_hundred_points_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>ğŸ˜</td>\n",
       "      <td>_beaming_face_with_smiling_eyes_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>ğŸ„</td>\n",
       "      <td>_Christmas_tree_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>ğŸ“¸</td>\n",
       "      <td>_camera_with_flash_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>ğŸ˜œ</td>\n",
       "      <td>_winking_face_with_tongue_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ğŸ˜‚</td>\n",
       "      <td>_face_with_tears_of_joy_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ğŸ’•</td>\n",
       "      <td>_two_hearts_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ğŸ”¥</td>\n",
       "      <td>_fire_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>ğŸ˜Š</td>\n",
       "      <td>_smiling_face_with_smiling_eyes_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>ğŸ˜</td>\n",
       "      <td>_smiling_face_with_sunglasses_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>âœ¨</td>\n",
       "      <td>_sparkles_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>ğŸ’™</td>\n",
       "      <td>_blue_heart_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>ğŸ˜˜</td>\n",
       "      <td>_face_blowing_a_kiss_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label emoji                              name\n",
       "0      0     â¤                       _red_heart_\n",
       "1      1     ğŸ˜     _smiling_face_with_hearteyes_\n",
       "10    10     ğŸ“·                          _camera_\n",
       "11    11    ğŸ‡ºğŸ‡¸                   _United_States_\n",
       "12    12     â˜€                             _sun_\n",
       "13    13     ğŸ’œ                    _purple_heart_\n",
       "14    14     ğŸ˜‰                    _winking_face_\n",
       "15    15     ğŸ’¯                  _hundred_points_\n",
       "16    16     ğŸ˜  _beaming_face_with_smiling_eyes_\n",
       "17    17     ğŸ„                  _Christmas_tree_\n",
       "18    18     ğŸ“¸               _camera_with_flash_\n",
       "19    19     ğŸ˜œ        _winking_face_with_tongue_\n",
       "2      2     ğŸ˜‚          _face_with_tears_of_joy_\n",
       "3      3     ğŸ’•                      _two_hearts_\n",
       "4      4     ğŸ”¥                            _fire_\n",
       "5      5     ğŸ˜Š  _smiling_face_with_smiling_eyes_\n",
       "6      6     ğŸ˜    _smiling_face_with_sunglasses_\n",
       "7      7     âœ¨                        _sparkles_\n",
       "8      8     ğŸ’™                      _blue_heart_\n",
       "9      9     ğŸ˜˜             _face_blowing_a_kiss_"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_mapping = pickle.load(open(file_names[\"df_us_mapping\"], \"rb\")).sort_values(\"label\")\n",
    "df_us_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           â¤       0.35      0.58      0.44     10798\n",
      "           ğŸ˜       0.25      0.25      0.25      4830\n",
      "           ğŸ“·       0.16      0.16      0.16      1432\n",
      "          ğŸ‡ºğŸ‡¸       0.47      0.50      0.48      1949\n",
      "           â˜€       0.25      0.43      0.32      1265\n",
      "           ğŸ’œ       0.32      0.05      0.08      1114\n",
      "           ğŸ˜‰       0.12      0.04      0.06      1306\n",
      "           ğŸ’¯       0.27      0.14      0.19      1244\n",
      "           ğŸ˜       0.14      0.03      0.05      1153\n",
      "           ğŸ„       0.60      0.60      0.60      1545\n",
      "           ğŸ“¸       0.29      0.10      0.15      2417\n",
      "           ğŸ˜œ       0.04      0.01      0.01      1010\n",
      "           ğŸ˜‚       0.30      0.52      0.38      4534\n",
      "           ğŸ’•       0.19      0.05      0.08      2605\n",
      "           ğŸ”¥       0.45      0.47      0.46      3716\n",
      "           ğŸ˜Š       0.09      0.06      0.07      1613\n",
      "           ğŸ˜       0.16      0.11      0.13      1996\n",
      "           âœ¨       0.29      0.18      0.22      2749\n",
      "           ğŸ’™       0.22      0.07      0.10      1549\n",
      "           ğŸ˜˜       0.16      0.05      0.08      1175\n",
      "\n",
      "    accuracy                           0.32     50000\n",
      "   macro avg       0.26      0.22      0.22     50000\n",
      "weighted avg       0.29      0.32      0.28     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test_bow)\n",
    "print(classification_report(df_us_test[\"label\"], y_pred, target_names=df_us_mapping[\"emoji\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {k: v for v, k in enumerate(vectorizer.get_feature_names_out())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "santa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.21267139, 0.10559105, 0.03170409, 0.02263593, 0.06533366,\n",
       "        0.01011697, 0.02992065, 0.00932074, 0.02055197, 0.11856118,\n",
       "        0.02276163, 0.02159743, 0.10988494, 0.03433423, 0.01711626,\n",
       "        0.03922043, 0.05487754, 0.02576475, 0.02707579, 0.02095938]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_test = np.zeros(X_train_bow.shape[1])\n",
    "k = vocab[\"santa\"]\n",
    "vec_test[k] = 1\n",
    "print(vectorizer.inverse_transform([vec_test])[0][0])\n",
    "clf.predict_proba([vec_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top palabras por emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 20s, sys: 999 ms, total: 1min 21s\n",
      "Wall time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vocab_length = X_train_bow.shape[1]\n",
    "proba_matrix = np.array([clf.predict_proba(np.eye(1,vocab_length,k))[0] for k in range(vocab_length)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29983\n",
      "(29983, 20)\n"
     ]
    }
   ],
   "source": [
    "print(vocab_length)\n",
    "print(proba_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29983,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "una_linea = proba_matrix[:,3]\n",
    "una_linea.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topPalabras(proba_matrix,emoji_id,k=5):\n",
    "    # retorna las palabras para las cuales el emoji en cuestiÃ³n tiene mas probabilidad\n",
    "    prob = proba_matrix[:,emoji_id]  # mmm\n",
    "    ind = np.argpartition(prob,-k)[-k:]\n",
    "    val = prob[ind]\n",
    "    palabras = [vectorizer.inverse_transform([np.eye(1,vocab_length,k)[0]])[0][0] for k in ind]\n",
    "    return palabras, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‡ºğŸ‡¸\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['murica', 'imwithher', 'election2016', 'ivoted', 'merica'],\n",
       " array([0.78007421, 0.8062308 , 0.83135636, 0.86388407, 0.8821097 ]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 3\n",
    "map_emojis = [0,1,10,11,12,13,14,15,16,17,18,19,2,3,4,5,6,7,8,9]\n",
    "print(df_us_mapping[\"emoji\"][map_emojis[i]])\n",
    "topPalabras(proba_matrix,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¤\n",
      "{'heart': 0.5761150508287712, 'valentines': 0.5811796285055364, 'lovemyfamily': 0.5793072574283205, 'valentine': 0.5949253260518091, 'loveofmylife': 0.6651429760457039}\n",
      "ğŸ˜\n",
      "{'inlove': 0.4288496011644503, 'gorg': 0.4453369489332203, 'obsessed': 0.44883209548006375, 'swoon': 0.45600734120528374, 'swooning': 0.4562752924146042}\n",
      "ğŸ“·\n",
      "{'sony': 0.3882939691961041, 'gdlfashion': 0.4052054276523981, 'bvillain': 0.5117380913776236, 'shredforaliving': 0.42318456197855087, 'kae': 0.4156412082407767}\n",
      "ğŸ‡ºğŸ‡¸\n",
      "{'murica': 0.7800742137338681, 'imwithher': 0.8062308003990193, 'election2016': 0.8313563588022287, 'ivoted': 0.8638840691974496, 'merica': 0.8821097001791353}\n",
      "â˜€\n",
      "{'soakin': 0.447527739339606, 'sun': 0.45989390878761877, 'sunny': 0.4740267973356278, 'sunshine': 0.5826999203405687, 'beachin': 0.4927352286841576}\n",
      "ğŸ’œ\n",
      "{'snyder': 0.3559341490500346, 'ripprince': 0.3575182172656461, 'endalz': 0.4398786494003444, 'purple': 0.5506017875276537, 'purplerain': 0.5134869871082338}\n",
      "ğŸ˜‰\n",
      "{'backtowork': 0.2129172475035178, 'wink': 0.23697450673018283, 'azek': 0.23901373031599815, 'silvercriketgentlemensclub': 0.23901373031599815, 'mividaesunatombola': 0.3304591357770921}\n",
      "ğŸ’¯\n",
      "{'t3t': 0.39850650010969246, 'keepin': 0.4169922638434261, 'facts': 0.5848465289708452, 'realtalk': 0.5061620053576262, 'rns': 0.47800047055538203}\n",
      "ğŸ˜\n",
      "{'dentist': 0.239497184608953, 'dentistry': 0.2741579803483271, 'cheesin': 0.28598242907316934, 'braces': 0.2908595553667064, 'djsty': 0.29970001389656153}\n",
      "ğŸ„\n",
      "{'tree': 0.5873939423592781, 'tis': 0.6204556185878153, 'christmas2015': 0.5925137901344447, 'merry': 0.5921571580626953, 'christmastree': 0.7896127824106279}\n",
      "ğŸ“¸\n",
      "{'cred': 0.3159050632200524, 'headshot': 0.3241125570492244, 'mag': 0.3337009742052551, 'opus': 0.4241583818170979, 'bricks': 0.34874909576037366}\n",
      "ğŸ˜œ\n",
      "{'burpees': 0.16219480409077416, 'jewelrydesigner': 0.17063599291164733, 'wacky': 0.18374154943712573, 'silly': 0.19345012616245877, 'cray': 0.22352568350963714}\n",
      "ğŸ˜‚\n",
      "{'funny': 0.709298339443829, 'wtf': 0.7376276034392985, 'lmfao': 0.8387500617307875, 'lmao': 0.8600667188416347, 'hilarious': 0.7794513567711954}\n",
      "ğŸ’•\n",
      "{'endorsement': 0.32348853465380645, 'lovealwaysyje': 0.33034960065978825, 'pink': 0.3544185518163782, 'strides': 0.3722537471026334, 'breast': 0.44012548234851656}\n",
      "ğŸ”¥\n",
      "{'flame': 0.6954472080681913, 'flames': 0.7013605810434306, 'fire': 0.702586754042741, 'mixtape': 0.7155634858236927, 'lit': 0.7075956742171502}\n",
      "ğŸ˜Š\n",
      "{'worlds2016': 0.27632029133395997, '7171': 0.2814042655159173, 'bagsbycab': 0.28184206439355336, '3037': 0.29394808945050926, '802': 0.2838469184935355}\n",
      "ğŸ˜\n",
      "{'beautique': 0.3566104881826646, 'shades': 0.4286315258210222, 'sunglasses': 0.5538250850510409, 'coolin': 0.3872564798469744, 'eyewear': 0.3732911260893004}\n",
      "âœ¨\n",
      "{'getonshimmur': 0.38076409557547336, 'sparkle': 0.55606315222639, 'glitter': 0.3824542997618393, 'magical': 0.4041663529709088, 'pixie': 0.41945855964929035}\n",
      "ğŸ’™\n",
      "{'rupp': 0.39496130878522095, 'foreverroyal': 0.43868663666132685, 'royals': 0.43887929760921546, 'autism': 0.4912285850528072, 'bbn': 0.44463409096380896}\n",
      "ğŸ˜˜\n",
      "{'kissy': 0.2835098942218612, 'kiss': 0.2998014122533109, 'kisses': 0.3778843629927282, 'smooches': 0.3331135467798145, 'princessmailyana': 0.28949959973025136}\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(df_us_mapping[\"emoji\"][map_emojis[i]])\n",
    "    pal, val = topPalabras(proba_matrix,i)\n",
    "    print(dict([(pal[j],val[j]) for j in range(len(pal))]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f20c33d1910a35bd4e57e72ae45c4ccb5c2a16c01a089293cb3a6910e8ec5b3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('datamining_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
